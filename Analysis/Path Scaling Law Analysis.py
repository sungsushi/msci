# -*- coding: utf-8 -*-
"""Copy of Copy of 1000_paths.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hszPEjiwGVp_xaxpyIch3CcuQC8lDOez

# 1000 paths 
## data from HPC
"""

import numpy as np
import matplotlib.pyplot as plt
"""import location code"""

"""# load"""

SmallGraphs = np.load(file=<pathway to file>.npy, allow_pickle=True)
BigGraphs = np.load(file=<pathway to file>.npy, allow_pickle=True)
BBigGraphs_1 = np.load(file=<pathway to file>.npy, allow_pickle=True)
BBigGraphs_2 = np.load(file=<pathway to file>.npy, allow_pickle=True)
BBBigGraphs_1 =  np.load(file=<pathway to file>.npy, allow_pickle=True)
BBBigGraphs_2 =  np.load(file=<pathway to file>.npy, allow_pickle=True)

#SmallGraphs

SmallGraphs_Ns = SmallGraphs[0]
SmallGraphs_realisations = SmallGraphs[1]
SmallGraphs_longest_path_points = SmallGraphs[2]
SmallGraphs_greedy_path_points = SmallGraphs[3]
SmallGraphs_random_path_points = SmallGraphs[4]

#BigGraphs

BigGraphs_Ns = BigGraphs[0]
BigGraphs_realisations = BigGraphs[1]
BigGraphs_longest_path_points = BigGraphs[2]
BigGraphs_greedy_path_points = BigGraphs[3]
BigGraphs_random_path_points = BigGraphs[4]

#BBigGraphs

BBigGraphs_Ns = BBigGraphs_1[0]
BBigGraphs_realisations = BBigGraphs_1[1] *2
BBigGraphs_longest_path_points = [BBigGraphs_1[2][0] + BBigGraphs_2[2][0], BBigGraphs_1[2][1] + BBigGraphs_2[2][1]]
BBigGraphs_greedy_path_points = [BBigGraphs_1[3][0] + BBigGraphs_2[3][0], BBigGraphs_1[3][1] + BBigGraphs_2[3][1]]
BBigGraphs_random_path_points = [BBigGraphs_1[4][0] + BBigGraphs_2[4][0], BBigGraphs_1[4][1] + BBigGraphs_2[4][1]]

#BBBigGraphs

BBBigGraphs_Ns = BBBigGraphs_1[0]
BBBigGraphs_realisations = BBBigGraphs_1[1]*2
BBBigGraphs_longest_path_points = [BBBigGraphs_1[2][0] + BBBigGraphs_2[2][0]]
BBBigGraphs_greedy_path_points = [BBBigGraphs_1[3][0] + BBBigGraphs_2[3][0]]
BBBigGraphs_random_path_points = [BBBigGraphs_1[4][0] + BBBigGraphs_2[4][0]]

mean_l_S_lengths = []
total_l_S_lengths = []
l_S_errors = []

mean_g_S_lengths = []
total_g_S_lengths = []
g_S_errors = []


mean_r_S_lengths = []
total_r_S_lengths = []
r_S_errors = []

for i in range(len(SmallGraphs_Ns)):
    l_lengths = []
    g_lengths = []
    r_lengths = []
    for j in range(SmallGraphs_realisations):
        l_lengths.append(len(SmallGraphs_longest_path_points[i][j])-1)
        g_lengths.append(len(SmallGraphs_greedy_path_points[i][j])-1)
        r_lengths.append(len(SmallGraphs_random_path_points[i][j])-1)
    total_l_S_lengths.append(l_lengths)
    mean_l_S_lengths.append(np.mean(l_lengths))
    l_S_errors.append(np.std(l_lengths)/np.sqrt(SmallGraphs_realisations))

    total_g_S_lengths.append(g_lengths)
    mean_g_S_lengths.append(np.mean(g_lengths))
    g_S_errors.append(np.std(g_lengths)/np.sqrt(SmallGraphs_realisations))

    total_r_S_lengths.append(r_lengths)
    mean_r_S_lengths.append(np.mean(r_lengths))
    r_S_errors.append(np.std(r_lengths)/np.sqrt(SmallGraphs_realisations))

mean_l_B_lengths = []
total_l_B_lengths = []
l_B_errors = []

mean_g_B_lengths = []
total_g_B_lengths = []
g_B_errors = []


mean_r_B_lengths = []
total_r_B_lengths = []
r_B_errors = []

for i in range(len(BigGraphs_Ns)):
    l_lengths = []
    g_lengths = []
    r_lengths = []
    for j in range(BigGraphs_realisations):
        l_lengths.append(len(BigGraphs_longest_path_points[i][j])-1)
        g_lengths.append(len(BigGraphs_greedy_path_points[i][j])-1)
        r_lengths.append(len(BigGraphs_random_path_points[i][j])-1)
    total_l_B_lengths.append(l_lengths)
    mean_l_B_lengths.append(np.mean(l_lengths))
    l_B_errors.append(np.std(l_lengths)/np.sqrt(BigGraphs_realisations))

    total_g_B_lengths.append(g_lengths)
    mean_g_B_lengths.append(np.mean(g_lengths))
    g_B_errors.append(np.std(g_lengths)/np.sqrt(BigGraphs_realisations))

    total_r_B_lengths.append(r_lengths)
    mean_r_B_lengths.append(np.mean(r_lengths))
    r_B_errors.append(np.std(r_lengths)/np.sqrt(BigGraphs_realisations))

mean_l_BB_lengths = []
total_l_BB_lengths = []
l_BB_errors = []

mean_g_BB_lengths = []
total_g_BB_lengths = []
g_BB_errors = []


mean_r_BB_lengths = []
total_r_BB_lengths = []
r_BB_errors = []

for i in range(len(BBigGraphs_Ns)):
    l_lengths = []
    g_lengths = []
    r_lengths = []
    for j in range(BBigGraphs_realisations):
        l_lengths.append(len(BBigGraphs_longest_path_points[i][j])-1)
        g_lengths.append(len(BBigGraphs_greedy_path_points[i][j])-1)
        r_lengths.append(len(BBigGraphs_random_path_points[i][j])-1)
    total_l_BB_lengths.append(l_lengths)
    mean_l_BB_lengths.append(np.mean(l_lengths))
    l_BB_errors.append(np.std(l_lengths)/np.sqrt(BBigGraphs_realisations))

    total_g_BB_lengths.append(g_lengths)
    mean_g_BB_lengths.append(np.mean(g_lengths))
    g_BB_errors.append(np.std(g_lengths)/np.sqrt(BBigGraphs_realisations))

    total_r_BB_lengths.append(r_lengths)
    mean_r_BB_lengths.append(np.mean(r_lengths))
    r_BB_errors.append(np.std(r_lengths)/np.sqrt(BBigGraphs_realisations))

mean_l_BBB_lengths = []
total_l_BBB_lengths = []
l_BBB_errors = []

mean_g_BBB_lengths = []
total_g_BBB_lengths = []
g_BBB_errors = []


mean_r_BBB_lengths = []
total_r_BBB_lengths = []
r_BBB_errors = []

for i in range(len(BBBigGraphs_Ns)):
    l_lengths = []
    g_lengths = []
    r_lengths = []
    for j in range(BBBigGraphs_realisations):
        l_lengths.append(len(BBBigGraphs_longest_path_points[i][j])-1)
        g_lengths.append(len(BBBigGraphs_greedy_path_points[i][j])-1)
        r_lengths.append(len(BBBigGraphs_random_path_points[i][j])-1)
    total_l_BBB_lengths.append(l_lengths)
    mean_l_BBB_lengths.append(np.mean(l_lengths))
    l_BBB_errors.append(np.std(l_lengths)/np.sqrt(BBBigGraphs_realisations))

    total_g_BBB_lengths.append(g_lengths)
    mean_g_BBB_lengths.append(np.mean(g_lengths))
    g_BBB_errors.append(np.std(g_lengths)/np.sqrt(BBBigGraphs_realisations))

    total_r_BBB_lengths.append(r_lengths)
    mean_r_BBB_lengths.append(np.mean(r_lengths))
    r_BBB_errors.append(np.std(r_lengths)/np.sqrt(BBBigGraphs_realisations))

realisations = [SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, BigGraphs_realisations, BigGraphs_realisations, BBigGraphs_realisations, BBigGraphs_realisations, BBBigGraphs_realisations]
Ns = SmallGraphs_Ns + BigGraphs_Ns + BBigGraphs_Ns + BBBigGraphs_Ns


mean_l_lengths = mean_l_S_lengths  + mean_l_B_lengths  + mean_l_BB_lengths  + mean_l_BBB_lengths 
mean_g_lengths = mean_g_S_lengths  + mean_g_B_lengths  + mean_g_BB_lengths  + mean_g_BBB_lengths 
mean_r_lengths = mean_r_S_lengths  + mean_r_B_lengths  + mean_r_BB_lengths  + mean_r_BBB_lengths 

l_errors = l_S_errors + l_B_errors + l_BB_errors + l_BBB_errors
g_errors = g_S_errors + g_B_errors + g_BB_errors + g_BBB_errors
r_errors = r_S_errors + r_B_errors + r_BB_errors + r_BBB_errors

fig, ax = plt.subplots(figsize=(7.5,6))

colours = ['#c44409', '#286f29', '#021461', '#710087']

plt.errorbar(np.log10(Ns), np.log10(mean_l_lengths), yerr= l_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= 'Longest path', color=colours[0])
plt.errorbar(np.log10(Ns), np.log10(mean_g_lengths), yerr= g_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= 'Time Greedy path', color=colours[2])
#plt.errorbar(np.log10(Ns), np.log10(mean_r_lengths), yerr= r_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= 'random path')



plt.plot(np.log10(Ns), np.log10(2*np.sqrt(Ns)), '--', label='Theory', color='green')
plt.xlabel("log(N)", size=30)
plt.ylabel("log(L)", size=30)
#

plt.legend()
plt.xticks(size=20)
plt.yticks(size=20)
#ax.set_xticks([0, 0.3, 0.6])
#ax.set_yticks([-2.6,-2, -1.4])
plt.legend(prop={'size': 19})
#plt.title(f'{realisations} realisations', size=30)
#plt.savefig('manypaths_scalingbig2.png', bbox_inches='tight')
#files.download('manypaths_scalingbig2.png')

plt.show()

fig, ax = plt.subplots(figsize=(7.5,6))
plt.errorbar(Ns, np.array(mean_l_lengths)/(2*np.sqrt(Ns)), yerr = np.array(l_errors)/(2*np.sqrt(Ns)), capsize = 5, fmt = '.', label= '$\\frac{L^+}{2\sqrt{{N}}}$' ,  color=colours[0])
plt.errorbar(Ns, np.array(mean_g_lengths)/(2*np.sqrt(Ns)), yerr = np.array(g_errors)/(2*np.sqrt(Ns)), capsize = 5, fmt = '.', label= '$\\frac{L_{{tg}}}{2\sqrt{{N}}}$',  color=colours[2])

plt.xlabel("No. of nodes, N", size=30)
plt.ylabel("Path length/Theory", size=30)
plt.legend()
plt.xscale('log')

plt.xticks(size=20)
plt.yticks(size=20)
ax.set_yticks([0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1])
#ax.set_yticks([-2.6,-2, -1.4])
plt.legend(prop={'size': 20})

plt.savefig('lpaths_fs2.png', bbox_inches='tight')
files.download('lpaths_fs2.png')
plt.show()

def straightline(x, m, c):
    return m*x + c

from scipy.optimize import curve_fit

#plt.plot(np.log10(Ns), mean_l_lengths, '.', label= f'longest path, {realisations} realisations')
#plt.plot(np.log10(Ns), mean_g_lengths, '.', label= f'greedy path, {realisations} realisations')
fig, ax = plt.subplots(figsize=(10,10))

log_Ns = np.log(Ns)
plt.errorbar(log_Ns, mean_r_lengths, yerr=r_errors, fmt ='.', capsize=5, label= f'Random path')
pars_1, cov_1 = curve_fit(f=straightline, xdata=log_Ns, ydata= mean_r_lengths, sigma=r_errors)
stdevs_1 = np.sqrt(np.diag(cov_1))
plt.plot(log_Ns, straightline(log_Ns, *pars_1), 'g--', label=fr' $L_r$ = {pars_1[0]:.2f} $\pm$ {stdevs_1[0]:.2f} $\ln(N)$ + {pars_1[1]:.2f} $\pm$ {stdevs_1[1]:.2f}  ')


#plt.plot(np.log10(Ns), np.log10(2*np.sqrt(Ns)), '--', label='log theory')
plt.xlabel("ln(N)", size=30)
plt.ylabel("path length", size=30)
plt.title(r"$L_r \propto \ln(N)$", size=30)
#

plt.legend()
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size':20})
ax.set_yticks([3, 4, 5, 6])
ax.set_xticks([2, 4, 6, 8])
plt.savefig('Random Paths Length Scaling.png')
files.download('Random Paths Length Scaling.png')

plt.show()

#plt.plot(np.log10(Ns), mean_l_lengths, '.', label= f'longest path, {realisations} realisations')
#plt.plot(np.log10(Ns), mean_g_lengths, '.', label= f'greedy path, {realisations} realisations')
fig, ax = plt.subplots(figsize=(10,10))

log_Ns = np.log(Ns)
plt.errorbar(log_Ns, np.log(mean_g_lengths), yerr=np.array(g_errors)/np.array(mean_g_lengths), fmt ='.', capsize=5, label= f'Time-Greedy path')
pars_1, cov_1 = curve_fit(f=straightline, xdata=log_Ns, ydata= np.log(mean_g_lengths), sigma=np.array(g_errors)/np.array(mean_g_lengths) )
stdevs_1 = np.sqrt(np.diag(cov_1))
plt.plot(log_Ns, straightline(log_Ns, *pars_1), 'g--', label=fr' $\ln(L_g)$ = {pars_1[0]:.2f} $\pm$ {stdevs_1[0]:.2f} $\ln(N)$ + {pars_1[1]:.2f} $\pm$ {stdevs_1[1]:.2f}  ')

plt.plot(log_Ns, 0.5*log_Ns + 0.5*np.log(2), '--', label='log theory')

plt.xlabel("ln(N)", size=30)
plt.ylabel("ln$(L_g)$", size=30)
plt.title(r"$L_g \propto \sqrt{N}$", size=30)
#


plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(loc = 'upper left',prop = {'size':20})
#ax.set_yticks([3, 4, 5, 6])
#ax.set_xticks([2, 4, 6, 8])
plt.savefig('Greedy Paths Length Scaling.png')
files.download('Greedy Paths Length Scaling.png')

plt.show()

1/(np.log10(2)*2)

np.exp(1/(2*pars_1[0] ))

np.sqrt(np.exp(1/pars_1[0]))

"""# Fitting """

log_Ns = np.log10(Ns)
log_l_lengths = np.log10(mean_l_lengths)
l_fit, cov =np.polyfit(log_Ns[4:], log_l_lengths[4:],1, w=l_errors[4:], cov=True)
stdevs_1 = np.sqrt(np.diag(cov))

l_fit_fcn=np.poly1d(l_fit)
plt.plot(log_Ns,l_fit_fcn(log_Ns),color="green")
plt.errorbar(log_Ns, log_l_lengths, yerr= l_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= 'longest path')
plt.xlabel("log no. of nodes")
plt.ylabel("log path length")
plt.title(fr" log $L^{{+}}$ = {l_fit[0]:.4} log N + {l_fit[1]:.4} ")
plt.legend()

#plt.savefig('lpath_scale_fit.png')
#files.download('lpath_scale_fit.png') 
plt.show()

stdevs_1

plt.plot(Ns, mean_l_lengths, 'o',  label= f'longest path, {realisations} realisations')
plt.plot(Ns, np.sqrt(Ns)*2 *(1 + -0.687*np.power(Ns, -0.333)), '--', label = "Theory")
plt.ylabel(r"$L^+$")
plt.xlabel("N")
plt.title("Poster theory vs model")
plt.legend()

#plt.savefig('postertheory_2.png')
#files.download('postertheory_2.png') 
plt.show()



log_g_lengths = np.log10(mean_g_lengths)

g_fit=np.polyfit(log_Ns, log_g_lengths,1)
g_fit_fcn=np.poly1d(g_fit)
plt.plot(log_Ns,g_fit_fcn(log_Ns), 'g--',  label=fr' $\log( L_g )$ = {g_fit[0]:.4} log N + {g_fit[1]:.4}' )
#plt.plot(log_Ns, 0.5*log_Ns+np.log10(np.sqrt(2)), 'r--', label=fr'Theory')


plt.errorbar(log_Ns, log_g_lengths, yerr= g_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= f'Time Greedy path') #, {realisations} realisations')
plt.xlabel("log no. of nodes")
plt.ylabel("log path length")
plt.title(fr" log G = {g_fit[0]:.4} log N + {g_fit[1]:.4} ")


plt.legend()

#plt.savefig('gpath_scale_fit.png')
#files.download('gpath_scale_fit.png')
plt.show()

fig, ax = plt.subplots(figsize=(7.5,6))

colours = ['#c44409', '#286f29', '#021461', '#710087']

log_Ns = np.log10(Ns)
log_l_err = l_errors*(1/(np.sqrt(np.log(10) * np.array(Ns))))
log_l_len = np.log10(mean_l_lengths)
plt.errorbar(log_Ns, log_l_len, 
             yerr= log_l_err, label = 'Longest path',
             fmt='.', capsize = 5, color=colours[0])

pars_l, cov_l = curve_fit(f=straightline, xdata=log_Ns[4:], ydata= log_l_len[4:], sigma = log_l_err[4:])
stdevs_l = np.sqrt(np.diag(cov_l))
#plt.plot(log_Ns, straightline(log_Ns, *pars_l), label=fr' $L^+$ = {pars_l[0]:.2f} $\pm$ {stdevs_l[0]:.2f} $\ln(N)$ + {pars_l[1]:.2f} $\pm$ {stdevs_l[1]:.2f}', color = colours[0])
#plt.plot(log_Ns, straightline(log_Ns, *pars_l), label=fr' $L^+$ = {pars_l[0]:.2f}(7) $\log(N)$ {pars_l[1]:.1f}(6)  ', color = colours[0])
#plt.plot(log_Ns, straightline(log_Ns, *pars_l), color = colours[0], alpha = 0.8)

l_D_eff = 1/pars_l[0]
l_D_eff_err = stdevs_l[0]*pars_l[0]*pars_l[0]
l_m_eff = np.power(10, pars_l[1])
l_m_eff_err = stdevs_l[1]/(np.log(10) * l_m_eff)

#plt.plot(log_Ns, straightline(log_Ns, *pars_l), label=fr' $D$ = {l_D_eff:.4f} $\pm$ {l_D_eff_err:.4f}, $m = $ {l_m_eff:.3f} $\pm$ {l_m_eff_err:.3f}', color = colours[0])
plt.plot(log_Ns, straightline(log_Ns, *pars_l), label=f' $D_+$ = {l_D_eff:.4f}(2)\n$m_+ = $ {l_m_eff:.3f}(2)', color = '#CF693A')


log_g_err = g_errors*(1/(np.sqrt(np.log(10) * np.array(Ns))))
log_g_len = np.log10(mean_g_lengths)
plt.errorbar(log_Ns, log_g_len, 
             yerr= log_g_err, label = 'T greedy path',
             fmt='.', capsize = 5, color=colours[2])

pars_g, cov_g = curve_fit(f=straightline, xdata=log_Ns[3:], ydata= log_g_len[3:], sigma = log_g_err[3:])
stdevs_g = np.sqrt(np.diag(cov_g))
#plt.plot(log_Ns, straightline(log_Ns, *pars_g), label=fr' $L_{{tg}}$ = {pars_g[0]:.5f} $\pm$ {stdevs_g[0]:.5f} $\ln(N)$ + {pars_g[1]:.4f} $\pm$ {stdevs_g[1]:.4f}', color = colours[2])
#plt.plot(log_Ns, straightline(log_Ns, *pars_g), label=fr' $L_{{tg}}$ = {pars_g[0]:.2f}(7) $\log(N)$ {pars_g[1]:.1f}(6)  ', color = colours[3])
#plt.plot(log_Ns, straightline(log_Ns, *pars_g), color = colours[2], alpha=0.8)


g_D_eff = 1/pars_g[0]
g_D_eff_err = stdevs_g[0]*pars_g[0]*pars_g[0]
g_m_eff = np.power(10, pars_g[1])
g_m_eff_err = stdevs_g[1]/(np.log(10) * g_m_eff)

#plt.plot(log_Ns, straightline(log_Ns, *pars_g), label=fr' $D$ = {g_D_eff:.4f} $\pm$ {g_D_eff_err:.4f}, $m = $ {g_m_eff:.3f} $\pm$ {g_m_eff_err:.3f}', color = colours[2])
plt.plot(log_Ns, straightline(log_Ns, *pars_g), label=f" $D_{{tg}}$ = {g_D_eff:.4f}(2)\n$m_{{tg}} = $ {g_m_eff:.3f}(1)", color = '#344280')



plt.plot(log_Ns, np.log10(2*np.sqrt(Ns)), '--', label='Theory', color='green')
plt.xlabel("log(N)", size=30)
plt.ylabel("log(L)", size=30)
#

plt.legend()
plt.xticks(size=20)
plt.yticks(size=20)
#ax.set_xticks([0, 0.3, 0.6])
#ax.set_yticks([-2.6,-2, -1.4])
plt.legend(prop={'size': 14})
#plt.title(f'{realisations} realisations', size=30)
#plt.savefig('ltg_len_scalingfit2.png', bbox_inches='tight')
#files.download('ltg_len_scalingfit2.png')

plt.show()

print(fr' $\log L^+$ = {pars_l[0]:.3f} $\pm$ {stdevs_l[0]:.3f} $\log(N)$ + {pars_l[1]:.3f} $\pm$ {stdevs_l[1]:.3f}')
print(fr' $\log L_{{tg}}$ = {pars_g[0]:.4f} $\pm$ {stdevs_g[0]:.4f} $\log(N)$ + {pars_g[1]:.3f} $\pm$ {stdevs_g[1]:.3f}')

log_r_lengths = np.log10(mean_r_lengths)

r_fit=np.polyfit(log_Ns, log_r_lengths,1)
r_fit_fcn=np.poly1d(r_fit)
plt.plot(log_Ns,r_fit_fcn(log_Ns),color="green")
plt.errorbar(log_Ns, log_r_lengths, yerr= r_errors*(1/(np.sqrt(np.log(10) * np.array(Ns)))), fmt='.', capsize = 5, label= f'Random path, {realisations} realisations')
plt.xlabel("log no. of nodes")
plt.ylabel("log path length")
plt.title(fr" log R = {r_fit[0]:.4} log N + {r_fit[1]:.4} ")
plt.legend()

#plt.savefig('rpath_scale_fit.png')
#files.download('rpath_scale_fit.png')
plt.show()

log_Ns

fig, ax = plt.subplots(figsize=(10,10))

colours = ['#c44409', '#286f29', '#021461', '#710087']


ys = np.log10(1- (np.array(mean_l_lengths)/(2*np.sqrt(Ns))))
log_Ns = np.log10(Ns)


correct_fit_fcn=np.poly1d([-0.2511, np.log10(0.3995)])
#correct_fit_fcn2=np.poly1d([-0.879, np.log10(0.333)])

#correct_fit_fcn2=np.poly1d([-0.333, np.log10(0.687)])
#plt.plot(log_Ns,correct_fit_fcn2(log_Ns),'r--', label = 'Literature 2', color = 'blue')


err = np.array(l_errors)/(2*np.sqrt(Ns) * np.log(10) * (-1 + np.array(mean_l_lengths)/(2*np.sqrt(Ns))))

pars_1, cov_1 = curve_fit(f=straightline, xdata=log_Ns, ydata= ys, sigma=err)
stdevs_1 = np.sqrt(np.diag(cov_1))
lm_fit_fcn=np.poly1d(pars_1)
#plt.plot(log_Ns, lm_fit_fcn(log_Ns), '-', label='Fit', color = 'green')


#more_fit=np.polyfit(log_Ns, ys, 1)
#more_fit_fcn=np.poly1d(more_fit)


#plt.plot(log_Ns,more_fit_fcn(log_Ns),color="green")


plt.errorbar(log_Ns, ys, yerr = err, capsize = 5, fmt = '.', label= '$\log( 1- L^+/2\sqrt{{N}})$')
plt.xlabel(r"$\log(N)$", size=30)
plt.ylabel(r"$\log( 1 - L^{{+}}/2\sqrt{{N}})$", size=30)
plt.legend(prop = {'size':25})
#plt.title(fr" $\log (1 - \frac{{L^{{+}}}}{{2 \sqrt{{N}}}})$ = {more_fit[0]:.4} log N + {more_fit[1]:.4} ", size=30)

#plt.title(fr' Gradient = {pars_1[0]:.3f} $\pm$ {stdevs_1[0]:.3f}, intercept =  {pars_1[1]:.2f} $\pm$ {stdevs_1[1]:.2f} ', size = 20)
#plt.title(fr' Gradient = {pars_1[0]:.3f}(3), intercept =  {pars_1[1]:.2f}(1) ', size = 20)


#litertature
plt.plot(log_Ns,correct_fit_fcn(log_Ns),'r--', label = 'R&W', color = 'red') # rideout and wallden


plt.xticks(size=20)
plt.yticks(size=20)
#ax.set_yticks([0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1])
#ax.set_yticks([-2.6,-2, -1.4])
plt.title("Longest Path Scalling, all N", fontsize = 30)
plt.legend(prop={'size': 20})

plt.savefig('lpath_cts_fit.png', bbox_inches='tight')
files.download('lpath_cts_fit.png')

plt.show()

pars_1

stdevs_1

def corrections2scaling(x, a, b):
    return 2 + a*np.exp(b*x)

from scipy.optimize import curve_fit

fig, ax = plt.subplots(figsize=(10,10))

colours = ['#c44409', '#286f29', '#021461', '#710087']

log_Ns = np.log(Ns)/np.log(2)

ys = np.array(mean_l_lengths)/np.sqrt(Ns)

#correct_fit_fcn=np.poly1d([-0.333, np.log10(0.687)])
#plt.plot(log_Ns,correct_fit_fcn(log_Ns),'r--', label = 'Theory', color = 'green')

#err = np.array(l_errors)/(2*np.sqrt(Ns) * np.log(10) * (-1 + np.array(mean_l_lengths)/(2*np.sqrt(Ns))))

pars_1, cov_1 = curve_fit(f=corrections2scaling, xdata=log_Ns, ydata= ys)
stdevs_1 = np.sqrt(np.diag(cov_1))
#lm_fit_fcn=np.poly1d(pars_1) 
#plt.plot(log_Ns, lm_fit_fcn(log_Ns), '--', label='Fit', color = 'red')


#more_fit=np.polyfit(log_Ns, ys, 1)
#more_fit_fcn=np.poly1d(more_fit)

x_s = np.arange(2, 18)

#err = np.array(l_errors)/(2*np.sqrt(Ns))
#plt.errorbar(log_Ns, ys, yerr = err, capsize = 5, fmt = 'o', label= 'Data')
plt.plot(log_Ns, ys, 'o', label= 'Data')
plt.xlabel(r"$\log_2(N)$", size=30)
plt.ylabel(r"$ L^{{+}}/2\sqrt{{N}}$", size=30)
plt.legend()
#plt.title(fr" $\log (1 - \frac{{L^{{+}}}}{{2 \sqrt{{N}}}})$ = {more_fit[0]:.4} log N + {more_fit[1]:.4} ", size=30)
#plt.title(fr' Gradient = {pars_1[0]:.3f} $\pm$ {stdevs_1[0]:.3f}, intercept =  {pars_1[1]:.3f} $\pm$ {stdevs_1[1]:.3f} ', size = 20)
#plt.title(fr' Gradient = {pars_1[0]:.3f}(3), intercept =  {pars_1[1]:.2f}(1) ', size = 20)

#plt.plot(log_Ns,more_fit_fcn(log_Ns),color="green")
plt.plot(x_s,corrections2scaling(x_s, *pars_1),color="green", label = 'fit')
plt.plot(x_s,corrections2scaling(x_s, a=-0.791, b = -0.1741), '--', color="red", label = 'R&W') # spacelike distance from discrete causal order Rideout and walden
plt.plot(x_s,corrections2scaling(x_s, a=-1.758, b = -np.log(2)/3),'--', color="blue", label = 'O&R') # odlyzko and rains 

plt.xticks(size=20)
plt.yticks(size=20)
plt.title("Comparing Our Fit to Existing Literature", fontsize = 30)
#ax.set_yticks([0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1])
#ax.set_yticks([-2.6,-2, -1.4])
plt.legend(prop={'size': 20})

plt.savefig('lit_scaling_comp.png', bbox_inches='tight')
files.download('lit_scaling_comp.png')

plt.show()

np.power(10, more_fit[1])

10**(-0.33)

np.log(10)*np.exp(-0.33 *np.log(10)) * 0.001

