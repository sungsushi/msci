# -*- coding: utf-8 -*-
"""Tidy Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14qV0ZeIG1YmKI8vxy2end2ODImcofWi9
"""

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import math
from scipy.optimize import curve_fit
from copy import deepcopy
from google.colab import files
from google.colab import drive
drive.mount('/content/drive')

#module loading without accessing colab again cause authorisation code every time is annoying

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import math
import copy
from scipy.optimize import curve_fit

!ls

"""#**Jagedness** - definitions"""

def get_angle(points):
  # points is an array of ordered coordinates which constitute the longest path
  angles = []
  for i in range(len(points) -2):
    v_1 = np.array(points[i]) - np.array(points[i+1])
    v_2 = np.array(points[i+2]) - np.array(points[i+1])

    costheta = np.dot(v_1,v_2) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))
    angles.append(np.arccos(costheta))
  return(angles)


def get_cosangle(points):
  # points is an array of ordered coordinates which constitute the longest path
  cosangles = []
  for i in range(len(points) -2):
    v_1 = np.array(points[i]) - np.array(points[i+1])
    v_2 = np.array(points[i+2]) - np.array(points[i+1])

    costheta = np.dot(v_1,v_2) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))
    cosangles.append(costheta)
  return(cosangles)


def get_angle2(points):
  # points is an array of ordered coordinates which constitute the longest path
  N = len(points)
  angles = []
  v_1 = np.array(points[:-2]) - np.array(points[1:-1])
  v_2 = np.array(points[2:]) - np.array(points[1:-1])
  #costheta = np.dot(v_1,v_2.T) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))  

  for i in range(len(v_1)):
    costheta = np.dot(v_1[i],v_2[i]) / (np.linalg.norm(v_1[i],2)*np.linalg.norm(v_2[i],2)) # does elementwise dot product exist? YES 
    angles.append(np.arccos(costheta))
  return(np.mean(angles))

"""#**Wonkiness** - Angle between edge and Local Rest Frame"""

def get_angle_LRF(points):
  #points defined as above
  angles = []
  for i in range(len(points)-1):
    v_1 = np.array(points[i+1]) - np.array(points[i])
    v_2 = np.array([0,1])   # Local rest frame will be a unit vector in t direction

    angles.append(np.arccos(np.dot(v_1,v_2) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))))
  return(angles)

def get_cosangle_LRF(points):
  # points is an array of ordered coordinates which constitute the longest path
  cosangles = []
  for i in range(len(points) -1):
    v_1 = np.array(points[i+1]) - np.array(points[i])
    v_2 = np.array([0,1])
    costheta = np.dot(v_1,v_2) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))
    cosangles.append(costheta)
  return(cosangles)

def get_angle2_LRF(points):
  # points is an array of ordered coordinates which constitute the longest path
  angles = []
  for i in range(len(points)-1):
    v_1 = np.array(points[i+1]) - np.array(points[i])
    v_2 = np.array([0,1])   # Local rest frame will be a unit vector in t direction
    angles.append(np.arccos(np.dot(v_1,v_2) / (np.linalg.norm(v_1,2)*np.linalg.norm(v_2,2))))
  return(np.mean(angles))

"""#**Wonkiness 2 elecctric Boogaloo**"""

def get_mink_angle_LRF(points):
  #points defined as above
  angles = []
  for i in range(len(points)-1):
    v = np.array(points[i+1]) - np.array(points[i])
    edge_length = np.sqrt(v[1]**2 - v[0]**2)
    angles.append(np.arccosh(v[1]/(edge_length)))
  return(angles)

"""#**Protrusion** - Maximum distance of path from geodesic"""

def protrusion(path):
  roughness = max(np.abs(path[:,0]))
  return roughness

"""#**Deviation** - Area deviation of path from geodesic"""

def area(path):
  #path is a list of node co-ords [(x_i,t_i)] of length whatever
  area = 0

  for i in range(len(path)-1):
    #consecutive nodes on same side of geodesic AND start/end nodes
    if path[i][0]*path[i+1][0] >= 0:
      area += 0.5 * abs(path[i][0] + path[i+1][0]) * abs(path[i][1] - path[i+1][1])
    #consecutive nodes on opposite sides of geodesic
    else:
      t_int = path[i][1] - path[i][0]* ((path[i+1][1] - path[i][1]) / (path[i+1][0] - path[i][0]))
      area += 0.5 * abs(path[i][0]) * abs(t_int - path[i][1])
      area += 0.5 * abs(path[i+1][0]) * abs(path[i+1][1] - t_int)
  return area

"""#**Curve fit definitions**"""

def lognormal(x,a,s,m):
  return a*np.exp(-np.power(np.log(x)-m, 2)/(2*np.power(s,2))) / (x*s*np.sqrt(2*np.pi))

def straightline(x,m,c):
  return m*x + c

"""#**Loading Paths**
run the version relevant to you

Saeed Version
"""

SmallGraphs = np.load(file='/content/drive/My Drive/Code for MSci/realisations/1000_paths.npy', allow_pickle=True)
BigGraphs = np.load(file='/content/drive/My Drive/Code for MSci/realisations/100_paths_BigGraphs.npy', allow_pickle=True)
BBigGraphs_1 = np.load(file='/content/drive/My Drive/Code for MSci/realisations/50_paths_BBigGraph_part1.npy', allow_pickle=True)
BBigGraphs_2 = np.load(file='/content/drive/My Drive/Code for MSci/realisations/50_paths_BBigGraph_part2.npy', allow_pickle=True)
BBBigGraphs_1 =  np.load(file='/content/drive/My Drive/Code for MSci/realisations/25_paths_1e5_part1.npy', allow_pickle=True)
BBBigGraphs_2 =  np.load(file='/content/drive/My Drive/Code for MSci/realisations/25_paths_1e5_part2.npy', allow_pickle=True)

"""Sung Soo Version"""

SmallGraphs = np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/1000_paths.npy', allow_pickle=True)
BigGraphs = np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/100_paths_BigGraphs.npy', allow_pickle=True)
BBigGraphs_1 = np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/50_paths_BBigGraph_part1.npy', allow_pickle=True)
BBigGraphs_2 = np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/50_paths_BBigGraph_part2.npy', allow_pickle=True)
BBBigGraphs_1 =  np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/25_paths_1e5_part1.npy', allow_pickle=True)
BBBigGraphs_2 =  np.load(file='/content/drive/My Drive/Colab Notebooks/msci/realisations/25_paths_1e5_part2.npy', allow_pickle=True)

"""#**Seperating out paths**

this is a lot of pointers, but should all be shallowcopies for now so not a big deal RAM wise
"""

#SmallGraphs

SmallGraphs_Ns = SmallGraphs[0]
SmallGraphs_realisations = SmallGraphs[1]
SmallGraphs_longest_path_points = SmallGraphs[2]
SmallGraphs_greedy_path_points = SmallGraphs[3]
SmallGraphs_random_path_points = SmallGraphs[4]

#BigGraphs

BigGraphs_Ns = BigGraphs[0]
BigGraphs_realisations = BigGraphs[1]
BigGraphs_longest_path_points = BigGraphs[2]
BigGraphs_greedy_path_points = BigGraphs[3]
BigGraphs_random_path_points = BigGraphs[4]

#BBigGraphs

BBigGraphs_Ns = BBigGraphs_1[0]
BBigGraphs_realisations = BBigGraphs_1[1] *2
BBigGraphs_longest_path_points = [BBigGraphs_1[2][0] + BBigGraphs_2[2][0], BBigGraphs_1[2][1] + BBigGraphs_2[2][1]]
BBigGraphs_greedy_path_points = [BBigGraphs_1[3][0] + BBigGraphs_2[3][0], BBigGraphs_1[3][1] + BBigGraphs_2[3][1]]
BBigGraphs_random_path_points = [BBigGraphs_1[4][0] + BBigGraphs_2[4][0], BBigGraphs_1[4][1] + BBigGraphs_2[4][1]]

#BBBigGraphs

BBBigGraphs_Ns = BBBigGraphs_1[0]
BBBigGraphs_realisations = BBBigGraphs_1[1]*2
BBBigGraphs_longest_path_points = [BBBigGraphs_1[2][0] + BBBigGraphs_2[2][0]]
BBBigGraphs_greedy_path_points = [BBBigGraphs_1[3][0] + BBBigGraphs_2[3][0]]
BBBigGraphs_random_path_points = [BBBigGraphs_1[4][0] + BBBigGraphs_2[4][0]]

"""#**Jaggedness**

**Unpacking and Errors**
"""

'''Bins'''

bins = np.arange(90,185,5)
bincenters = 0.5*(bins[1:]+bins[:-1])
N_i = -1



'''
--------------------------------------------------------------------------------
SmallGraphs'''
#paths
l_S_jagged, g_S_jagged, r_S_jagged = [], [], [] 

#errors 
# standard error of the mean of the frequencies in each bin, for each graph size. List of arrays.
l_S_jagged_errs, g_S_jagged_errs, r_S_jagged_errs =[], [], [] 

#meanf
# mean frequency in each bin, for each graph size. List of arrays. 
l_S_jagged_meanf, g_S_jagged_meanf, r_S_jagged_meanf =[], [], []

#n_total
# mean (over realisations) total number of angles, for each graph size. List. 
l_S_jagged_nTotal, g_S_jagged_nTotal, r_S_jagged_nTotal =[], [], []

#n_errs
# standard error of the mean in the total frequency, for each graph size. 
l_S_jagged_nErrs, g_S_jagged_nErrs, r_S_jagged_nErrs =[], [], []

#Unpacking Jaggedness
for i in range(len(SmallGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_S_jagged, N_G_S_jagged, N_R_S_jagged = [], [], []
  
  for j in range(SmallGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle(SmallGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle(SmallGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle(SmallGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_S_jagged.append(angles_of_lp)
    N_G_S_jagged.append(angles_of_gp)
    N_R_S_jagged.append(angles_of_rp)
 
  l_S_jagged.append(N_L_S_jagged)
  g_S_jagged.append(N_G_S_jagged)
  r_S_jagged.append(N_R_S_jagged)

#Errors
for i in range(len(SmallGraphs_Ns)):
  l_S_freq, g_S_freq, r_S_freq =[], [], []
  l_S_n, g_S_n, r_S_n = [], [], []

  for j in range(SmallGraphs_realisations):
    yl_S, l_S_binEdges = np.histogram(l_S_jagged[i][j], bins=bins, density=False)
    yg_S, g_S_binEdges = np.histogram(g_S_jagged[i][j], bins=bins, density=False)
    yr_S, r_S_binEdges = np.histogram(r_S_jagged[i][j], bins=bins, density=False)

    l_S_freq.append(yl_S)
    g_S_freq.append(yg_S)
    r_S_freq.append(yr_S)

    l_S_n.append(np.sum(yl_S))
    g_S_n.append(np.sum(yg_S))
    r_S_n.append(np.sum(yr_S))
  
  l_S_freq = np.array(l_S_freq)
  g_S_freq = np.array(g_S_freq)
  r_S_freq = np.array(r_S_freq)

  l_S_jagged_meanf.append(np.mean(l_S_freq, axis=0))
  g_S_jagged_meanf.append(np.mean(g_S_freq, axis=0))
  r_S_jagged_meanf.append(np.mean(r_S_freq, axis=0))

  l_S_jagged_errs.append(np.std(l_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  g_S_jagged_errs.append(np.std(g_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  r_S_jagged_errs.append(np.std(r_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))

  l_S_jagged_nTotal.append(np.mean(l_S_n))
  g_S_jagged_nTotal.append(np.mean(g_S_n))
  r_S_jagged_nTotal.append(np.mean(r_S_n))

  l_S_jagged_nErrs.append(np.std(l_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  g_S_jagged_nErrs.append(np.std(g_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  r_S_jagged_nErrs.append(np.std(r_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))




'''
--------------------------------------------------------------------------------
BigGraphs'''

#paths
l_B_jagged, g_B_jagged, r_B_jagged = [], [], []

#errors
l_B_jagged_errs, g_B_jagged_errs, r_B_jagged_errs =[], [], []

#meanf
l_B_jagged_meanf, g_B_jagged_meanf, r_B_jagged_meanf =[], [], []

#n_total
l_B_jagged_nTotal, g_B_jagged_nTotal, r_B_jagged_nTotal =[], [], []

#n_errs
l_B_jagged_nErrs, g_B_jagged_nErrs, r_B_jagged_nErrs =[], [], []

#Unpacking Jaggedness
for i in range(len(BigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_B_jagged, N_G_B_jagged, N_R_B_jagged = [], [], []
  
  for j in range(BigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle(BigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle(BigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle(BigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_B_jagged.append(angles_of_lp)
    N_G_B_jagged.append(angles_of_gp)
    N_R_B_jagged.append(angles_of_rp)
 
  l_B_jagged.append(N_L_B_jagged)
  g_B_jagged.append(N_G_B_jagged)
  r_B_jagged.append(N_R_B_jagged)

#Errors
for i in range(len(BigGraphs_Ns)):
  l_B_freq, g_B_freq, r_B_freq =[], [], []
  l_B_n, g_B_n, r_B_n = [], [], []

  for j in range(BigGraphs_realisations):
    yl_B, l_B_binEdges = np.histogram(l_B_jagged[i][j], bins=bins, density=False)
    yg_B, g_B_binEdges = np.histogram(g_B_jagged[i][j], bins=bins, density=False)
    yr_B, r_B_binEdges = np.histogram(r_B_jagged[i][j], bins=bins, density=False)

    l_B_freq.append(yl_B)
    g_B_freq.append(yg_B)
    r_B_freq.append(yr_B)

    l_B_n.append(np.sum(yl_B))
    g_B_n.append(np.sum(yg_B))
    r_B_n.append(np.sum(yr_B))
  
  l_B_freq = np.array(l_B_freq)
  g_B_freq = np.array(g_B_freq)
  r_B_freq = np.array(r_B_freq)

  l_B_jagged_meanf.append(np.mean(l_B_freq, axis=0))
  g_B_jagged_meanf.append(np.mean(g_B_freq, axis=0))
  r_B_jagged_meanf.append(np.mean(r_B_freq, axis=0))

  l_B_jagged_errs.append(np.std(l_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  g_B_jagged_errs.append(np.std(g_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  r_B_jagged_errs.append(np.std(r_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))

  l_B_jagged_nTotal.append(np.mean(l_B_n))
  g_B_jagged_nTotal.append(np.mean(g_B_n))
  r_B_jagged_nTotal.append(np.mean(r_B_n))

  l_B_jagged_nErrs.append(np.std(l_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  g_B_jagged_nErrs.append(np.std(g_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  r_B_jagged_nErrs.append(np.std(r_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))





'''
--------------------------------------------------------------------------------
BBigGraphs'''

#paths
l_BB_jagged, g_BB_jagged, r_BB_jagged = [], [], []

#errors
l_BB_jagged_errs, g_BB_jagged_errs, r_BB_jagged_errs =[], [], []

#meanf
l_BB_jagged_meanf, g_BB_jagged_meanf, r_BB_jagged_meanf =[], [], []

#n_total
l_BB_jagged_nTotal, g_BB_jagged_nTotal, r_BB_jagged_nTotal =[], [], []

#n_errs
l_BB_jagged_nErrs, g_BB_jagged_nErrs, r_BB_jagged_nErrs =[], [], []

#Unpacking Jaggedness
for i in range(len(BBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BB_jagged, N_G_BB_jagged, N_R_BB_jagged = [], [], []
  
  for j in range(BBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle(BBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle(BBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle(BBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BB_jagged.append(angles_of_lp)
    N_G_BB_jagged.append(angles_of_gp)
    N_R_BB_jagged.append(angles_of_rp)
 
  l_BB_jagged.append(N_L_BB_jagged)
  g_BB_jagged.append(N_G_BB_jagged)
  r_BB_jagged.append(N_R_BB_jagged)

#Errors
for i in range(len(BBigGraphs_Ns)):
  l_BB_freq, g_BB_freq, r_BB_freq =[], [], []
  l_BB_n, g_BB_n, r_BB_n = [], [], []

  for j in range(BBigGraphs_realisations):
    yl_BB, l_BB_binEdges = np.histogram(l_BB_jagged[i][j], bins=bins, density=False)
    yg_BB, g_BB_binEdges = np.histogram(g_BB_jagged[i][j], bins=bins, density=False)
    yr_BB, r_BB_binEdges = np.histogram(r_BB_jagged[i][j], bins=bins, density=False)

    l_BB_freq.append(yl_BB)
    g_BB_freq.append(yg_BB)
    r_BB_freq.append(yr_BB)

    l_BB_n.append(np.sum(yl_BB))
    g_BB_n.append(np.sum(yg_BB))
    r_BB_n.append(np.sum(yr_BB))
  
  l_BB_freq = np.array(l_BB_freq)
  g_BB_freq = np.array(g_BB_freq)
  r_BB_freq = np.array(r_BB_freq)

  l_BB_jagged_meanf.append(np.mean(l_BB_freq, axis=0))
  g_BB_jagged_meanf.append(np.mean(g_BB_freq, axis=0))
  r_BB_jagged_meanf.append(np.mean(r_BB_freq, axis=0))

  l_BB_jagged_errs.append(np.std(l_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  g_BB_jagged_errs.append(np.std(g_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  r_BB_jagged_errs.append(np.std(r_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))

  l_BB_jagged_nTotal.append(np.mean(l_BB_n))
  g_BB_jagged_nTotal.append(np.mean(g_BB_n))
  r_BB_jagged_nTotal.append(np.mean(r_BB_n))

  l_BB_jagged_nErrs.append(np.std(l_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  g_BB_jagged_nErrs.append(np.std(g_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  r_BB_jagged_nErrs.append(np.std(r_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))




'''
--------------------------------------------------------------------------------
BBBigGraphs'''

#paths
l_BBB_jagged, g_BBB_jagged, r_BBB_jagged = [], [], []

#errors
l_BBB_jagged_errs, g_BBB_jagged_errs, r_BBB_jagged_errs =[], [], []

#meanf
l_BBB_jagged_meanf, g_BBB_jagged_meanf, r_BBB_jagged_meanf =[], [], []

#n_total
l_BBB_jagged_nTotal, g_BBB_jagged_nTotal, r_BBB_jagged_nTotal =[], [], []

#n_errs
l_BBB_jagged_nErrs, g_BBB_jagged_nErrs, r_BBB_jagged_nErrs =[], [], []

#Unpacking Jaggedness
for i in range(len(BBBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BBB_jagged, N_G_BBB_jagged, N_R_BBB_jagged = [], [], []
  
  for j in range(BBBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle(BBBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle(BBBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle(BBBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BBB_jagged.append(angles_of_lp)
    N_G_BBB_jagged.append(angles_of_gp)
    N_R_BBB_jagged.append(angles_of_rp)
 
  l_BBB_jagged.append(N_L_BBB_jagged)
  g_BBB_jagged.append(N_G_BBB_jagged)
  r_BBB_jagged.append(N_R_BBB_jagged)


#Errors
for i in range(len(BBBigGraphs_Ns)):
  l_BBB_freq, g_BBB_freq, r_BBB_freq =[], [], []
  l_BBB_n, g_BBB_n, r_BBB_n = [], [], []

  for j in range(BBBigGraphs_realisations):
    yl_BBB, l_BBB_binEdges = np.histogram(l_BBB_jagged[i][j], bins=bins, density=False)
    yg_BBB, g_BBB_binEdges = np.histogram(g_BBB_jagged[i][j], bins=bins, density=False)
    yr_BBB, r_BBB_binEdges = np.histogram(r_BBB_jagged[i][j], bins=bins, density=False)

    l_BBB_freq.append(yl_BBB)
    g_BBB_freq.append(yg_BBB)
    r_BBB_freq.append(yr_BBB)

    l_BBB_n.append(np.sum(yl_BBB))
    g_BBB_n.append(np.sum(yg_BBB))
    r_BBB_n.append(np.sum(yr_BBB))
  
  l_BBB_freq = np.array(l_BBB_freq)
  g_BBB_freq = np.array(g_BBB_freq)
  r_BBB_freq = np.array(r_BBB_freq)

  l_BBB_jagged_meanf.append(np.mean(l_BBB_freq, axis=0))
  g_BBB_jagged_meanf.append(np.mean(g_BBB_freq, axis=0))
  r_BBB_jagged_meanf.append(np.mean(r_BBB_freq, axis=0))

  l_BBB_jagged_errs.append(np.std(l_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  g_BBB_jagged_errs.append(np.std(g_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  r_BBB_jagged_errs.append(np.std(r_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))

  l_BBB_jagged_nTotal.append(np.mean(l_BBB_n))
  g_BBB_jagged_nTotal.append(np.mean(g_BBB_n))
  r_BBB_jagged_nTotal.append(np.mean(r_BBB_n))

  l_BBB_jagged_nErrs.append(np.std(l_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  g_BBB_jagged_nErrs.append(np.std(g_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  r_BBB_jagged_nErrs.append(np.std(r_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))




'''
<l/g/r>_<batch (S/B/BB/BBB)>_jagged_



'''

"""**Union**"""

#realisations union
realisations = [SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, BigGraphs_realisations, BigGraphs_realisations, BBigGraphs_realisations, BBigGraphs_realisations, BBBigGraphs_realisations]
#Ns union
Ns = SmallGraphs_Ns + BigGraphs_Ns + BBigGraphs_Ns + BBBigGraphs_Ns

#raw jaggedness union
l_jagged = l_S_jagged + l_B_jagged + l_BB_jagged + l_BBB_jagged
g_jagged = g_S_jagged + g_B_jagged + g_BB_jagged + g_BBB_jagged
r_jagged = r_S_jagged + r_B_jagged + r_BB_jagged + r_BBB_jagged

#nErrs union
l_jagged_nErrs = l_S_jagged_nErrs + l_B_jagged_nErrs + l_BB_jagged_nErrs + l_BBB_jagged_nErrs 
g_jagged_nErrs = g_S_jagged_nErrs + g_B_jagged_nErrs + g_BB_jagged_nErrs + g_BBB_jagged_nErrs
r_jagged_nErrs = r_S_jagged_nErrs + r_B_jagged_nErrs + r_BB_jagged_nErrs + r_BBB_jagged_nErrs

#meanf union
l_jagged_meanf = l_S_jagged_meanf + l_B_jagged_meanf + l_BB_jagged_meanf + l_BBB_jagged_meanf 
g_jagged_meanf = g_S_jagged_meanf + g_B_jagged_meanf + g_BB_jagged_meanf + g_BBB_jagged_meanf
r_jagged_meanf = r_S_jagged_meanf + r_B_jagged_meanf + r_BB_jagged_meanf + r_BBB_jagged_meanf

#nTotal union
l_jagged_nTotal = l_S_jagged_nTotal + l_B_jagged_nTotal + l_BB_jagged_nTotal + l_BBB_jagged_nTotal
g_jagged_nTotal = g_S_jagged_nTotal + g_B_jagged_nTotal + g_BB_jagged_nTotal + g_BBB_jagged_nTotal
r_jagged_nTotal = r_S_jagged_nTotal + r_B_jagged_nTotal + r_BB_jagged_nTotal + r_BBB_jagged_nTotal

#errs union
l_jagged_errs = l_S_jagged_errs +  l_B_jagged_errs + l_BB_jagged_errs + l_BBB_jagged_errs
g_jagged_errs = g_S_jagged_errs +  g_B_jagged_errs + g_BB_jagged_errs + g_BBB_jagged_errs
r_jagged_errs = r_S_jagged_errs +  r_B_jagged_errs + r_BB_jagged_errs + r_BBB_jagged_errs

"""**Plotting**"""

#plt.figure(figsize=(40,40))
#plt.suptitle('Jaggedness distribution from various graph sizes', fontsize=30)

l_LastBin, l_LastBinErr = [], []
g_LastBin, g_LastBinErr = [], []
r_LastBin, r_LastBinErr = [], []

for i in range(len(Ns)):
  #plt.subplot(4,4,i+1)
  plt.figure(figsize=(10,10))

  yl, l_binEdges = np.histogram(np.concatenate(l_jagged[i],axis = None), bins=bins, density=False)
  l_Nerror = np.sqrt((l_jagged_nErrs[i] * (l_jagged_meanf[i]/ (l_jagged_nTotal[i]**2)))**2 + (l_jagged_errs[i]/l_jagged_nTotal[i])**2)/5
  l_LastBin.append(yl[17]/(5*len(np.concatenate(l_jagged[i],axis = None))))
  l_LastBinErr.append(l_Nerror[17])

  yg, g_binEdges = np.histogram(np.concatenate(g_jagged[i],axis = None), bins=bins, density=False)
  g_Nerror = np.sqrt((g_jagged_nErrs[i] * (g_jagged_meanf[i]/ (g_jagged_nTotal[i]**2)))**2 + (g_jagged_errs[i]/g_jagged_nTotal[i])**2)/5 
  g_LastBin.append(yg[17]/(5*len(np.concatenate(g_jagged[i],axis = None))))
  g_LastBinErr.append(g_Nerror[17])

  yr, r_binEdges = np.histogram(np.concatenate(r_jagged[i],axis = None), bins=bins, density=False)
  r_Nerror = np.sqrt((r_jagged_nErrs[i] * (r_jagged_meanf[i]/ (r_jagged_nTotal[i]**2)))**2 + (r_jagged_errs[i]/r_jagged_nTotal[i])**2)/5 
  r_LastBin.append(yr[17]/(5*len(np.concatenate(r_jagged[i],axis = None))))
  r_LastBinErr.append(r_Nerror[17])

  plt.errorbar(bincenters, yl/(5*len(np.concatenate(l_jagged[i],axis = None))), fmt ='.', yerr=l_Nerror, capsize=5, label='Longest path')
  plt.errorbar(bincenters, yg/(5*len(np.concatenate(g_jagged[i],axis = None))), fmt ='.', yerr=g_Nerror, capsize=5, label='Greedy path')
  plt.errorbar(bincenters, yr/(5*len(np.concatenate(r_jagged[i],axis = None))), fmt ='.', yerr=r_Nerror, capsize=5, label='Random path')

  plt.legend(prop={'size': 25})
  plt.xlabel(r' $\theta$', fontsize =25)
  plt.ylabel('Probability Density', fontsize = 25)
  plt.title(rf'Jaggedness for N={Ns[i]}, Realisations={realisations[i]}', fontsize =30)
  plt.xticks(size=20)
  plt.yticks(size=20)

  plt.show()
  #plt.savefig('Raw Jaggedness {Ns[i]}.png')
  #files.download('Raw Jaggedness {Ns[i]}.png')

"""**How does P(last bin) change with N?**"""

plt.figure(figsize=(10,10))
plt.title('Jaggedness - P(last Bin) as a function of N', fontsize =30)

plt.errorbar(np.log10(Ns), l_LastBin, fmt='.', yerr = l_LastBinErr, capsize = 5, label = 'Longest Path')
plt.errorbar(np.log10(Ns), g_LastBin, fmt='.', yerr = g_LastBinErr, capsize = 5, label = 'Greedy Path')
plt.errorbar(np.log10(Ns), r_LastBin, fmt='.', yerr = r_LastBinErr, capsize = 5, label = 'Random Path')

plt.legend(prop={'size': 25})
plt.xlabel('log(N), Size of Graph', fontsize =25)
plt.ylabel('Probability of Jaggedness $\in (175,180)^{\circ}$)', fontsize =25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.show()

"""#**Protusion**

**calculating protrusions**
"""

'''
--------------------------------------------------------------------------------
SmallGraphs'''
#paths
l_S_prot, g_S_prot, r_S_prot = [], [], [] 

#Unpacking Protrusion
for i in range(len(SmallGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_S_prot, N_G_S_prot, N_R_S_prot = [], [], []
  
  for j in range(SmallGraphs_realisations):
    #add in those angles to this array
    N_L_S_prot.append(protrusion(SmallGraphs_longest_path_points[i][j]))
    N_G_S_prot.append(protrusion(SmallGraphs_greedy_path_points[i][j]))
    N_R_S_prot.append(protrusion(SmallGraphs_random_path_points[i][j]))
 
  l_S_prot.append(N_L_S_prot)
  g_S_prot.append(N_G_S_prot)
  r_S_prot.append(N_R_S_prot)
  



'''
--------------------------------------------------------------------------------
BigGraphs'''
#paths
l_B_prot, g_B_prot, r_B_prot = [], [], [] 

#Unpacking Protrusion
for i in range(len(BigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_B_prot, N_G_B_prot, N_R_B_prot = [], [], []
  
  for j in range(BigGraphs_realisations):
    #add in those angles to this array
    N_L_B_prot.append(protrusion(BigGraphs_longest_path_points[i][j]))
    N_G_B_prot.append(protrusion(BigGraphs_greedy_path_points[i][j]))
    N_R_B_prot.append(protrusion(BigGraphs_random_path_points[i][j]))
 
  l_B_prot.append(N_L_B_prot)
  g_B_prot.append(N_G_B_prot)
  r_B_prot.append(N_R_B_prot)




'''
--------------------------------------------------------------------------------
BBigGraphs'''
#paths
l_BB_prot, g_BB_prot, r_BB_prot = [], [], [] 

#Unpacking Protrusion
for i in range(len(BBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BB_prot, N_G_BB_prot, N_R_BB_prot = [], [], []
  
  for j in range(BBigGraphs_realisations):
    #add in those angles to this array
    N_L_BB_prot.append(protrusion(BBigGraphs_longest_path_points[i][j]))
    N_G_BB_prot.append(protrusion(BBigGraphs_greedy_path_points[i][j]))
    N_R_BB_prot.append(protrusion(BBigGraphs_random_path_points[i][j]))
 
  l_BB_prot.append(N_L_BB_prot)
  g_BB_prot.append(N_G_BB_prot)
  r_BB_prot.append(N_R_BB_prot)




'''
--------------------------------------------------------------------------------
BBBigGraphs'''
#paths
l_BBB_prot, g_BBB_prot, r_BBB_prot = [], [], [] 

#Unpacking Protrusion
for i in range(len(BBBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BBB_prot, N_G_BBB_prot, N_R_BBB_prot = [], [], []
  
  for j in range(BBBigGraphs_realisations):
    #add in those angles to this array
    N_L_BBB_prot.append(protrusion(BBBigGraphs_longest_path_points[i][j]))
    N_G_BBB_prot.append(protrusion(BBBigGraphs_greedy_path_points[i][j]))
    N_R_BBB_prot.append(protrusion(BBBigGraphs_random_path_points[i][j]))
 
  l_BBB_prot.append(N_L_BBB_prot)
  g_BBB_prot.append(N_G_BBB_prot)
  r_BBB_prot.append(N_R_BBB_prot)

"""**union of data**"""

#realisations union
realisations = [SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, BigGraphs_realisations, BigGraphs_realisations, BBigGraphs_realisations, BBigGraphs_realisations, BBBigGraphs_realisations]
#Ns union
Ns = SmallGraphs_Ns + BigGraphs_Ns + BBigGraphs_Ns + BBBigGraphs_Ns

#raw protrusion union
l_prot = l_S_prot + l_B_prot + l_BB_prot + l_BBB_prot
g_prot = g_S_prot + g_B_prot + g_BB_prot + g_BBB_prot
r_prot = r_S_prot + r_B_prot + r_BB_prot + r_BBB_prot

#no special errors to merge

"""**Plots**"""

#definitions
yl, yg, yr = [0]*12,[0]*12,[0]*12
binEdge_l, binEdge_g, binEdge_r = [0]*12,[0]*12,[0]*12
binCenters_l, binCenters_g, binCenters_r = [0]*12,[0]*12,[0]*12
menStd_l, menStd_g, menStd_r = [0]*12,[0]*12,[0]*12

#Main plot
plt.figure(figsize=(40,40))
plt.suptitle('Protrusion distribution from various graph sizes', fontsize= 18)

#subplots
for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #longest
  yl[i], binEdge_l[i] = np.histogram(l_prot[i], bins = 20, density = False)
  binCenters_l[i] = 0.5*(binEdge_l[i][1:] + binEdge_l[i][:-1])
  menStd_l[i] = np.sqrt(yl[i])

  plt.errorbar(binCenters_l[i], yl[i], fmt = '.', yerr = menStd_l[i], capsize=5, label = 'Longest Path')

  #greedy
  yg[i], binEdge_g[i] = np.histogram(g_prot[i], bins = 20, density = False)
  binCenters_g[i] = 0.5*(binEdge_g[i][1:] + binEdge_g[i][:-1])
  menStd_g[i] = np.sqrt(yg[i])

  plt.errorbar(binCenters_g[i], yg[i], fmt = '.', yerr = menStd_g[i], capsize=5, label = 'Greedy Path')

  #random
  yr[i], binEdge_r[i] = np.histogram(r_prot[i], bins = 20, density = False)
  binCenters_r[i] = 0.5*(binEdge_r[i][1:] + binEdge_r[i][:-1])
  menStd_r[i] = np.sqrt(yr[i])

  plt.errorbar(binCenters_r[i], yr[i], fmt = '.', yerr = menStd_r[i], capsize=5, label = 'Random Path')
  
  #graph stuff
  plt.legend()
  plt.xlabel('Protrusion')
  plt.ylabel('Frequency')
  plt.title(f'Protrusion in graph size {Ns[i]}, realisations: {realisations[i]}')

plt.show()

"""**Lognormal Fits for Longest Path**"""

#defintions
s_s_l, m_s_l, a_s_l = [],[],[]
s_errs_l, m_errs_l, a_errs_l = [],[],[]


plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Longest Path Protrusion', fontsize = 30)


for i in range(len(Ns)):
  plt.subplot(4,4,i+1)
  #plt.figure(figsize =(10,10))

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_l[i], ydata=yl[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_l.append(pars[0])
  s_s_l.append(pars[1])
  m_s_l.append(pars[2])
  #parameter errors
  a_errs_l.append(stdevs[0])
  s_errs_l.append(stdevs[1])
  m_errs_l.append(stdevs[2])
  
  #lognormal plot itself
  x = np.linspace(0.02, 0.6, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_l[i], yl[i], fmt = '.', yerr = menStd_l[i], capsize=5, label = 'Longest Path')

  #plotting stuff
  plt.legend(prop={'size':15})
  plt.xlabel('Longest Path Protrusion', fontsize = 20)
  plt.ylabel('Frequency', fontsize = 20)
  plt.title(f'Protrusions for N={Ns[i]}, Realisations={realisations[i]}', fontsize =25)
  plt.xticks(size=20)
  plt.yticks(size=20)


plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_l[Key_Ns[i]], ydata=yl[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_l[Key_Ns[i]], yl[Key_Ns[i]], fmt = '.', yerr = menStd_l[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Protrusions of the Longest Path', fontsize = 30)
plt.xlabel(r'Protrusion, $\Delta x$', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()



"""**Longest Path Parameter Scaling**"""

plt.figure(figsize=(20,20))
plt.suptitle('Longest Path Protrusion Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_l, fmt='o', yerr=s_errs_l, capsize = 5)
plt.title("s Scaling", fontsize = 25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("s", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)



plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_l, fmt='o', yerr=m_errs_l, capsize = 5)
plt.title("m Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)


#plt.subplot(3,3,3)
#plt.errorbar(Ns, a_s_l, fmt='o', yerr=a_errs_l, capsize = 5)
#plt.title("A scaling", fontsize =15)
#plt.xlabel("N, size of graph", fontsize =15)
#plt.ylabel("A", fontsize =15)
#plt.xscale('log')


plt.subplot(2,2,2)

plt.show()

"""**Lognormal Fits for Greedy Paths**"""

#defintions
s_s_g, m_s_g, a_s_g = [],[],[]
s_errs_g, m_errs_g, a_errs_g = [],[],[]

#figure stuff
plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Greedy Path Protrusion', fontsize = 30)

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_g[i], ydata=yg[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_g.append(pars[0])
  s_s_g.append(pars[1])
  m_s_g.append(pars[2])
  #parameter errors
  a_errs_g.append(stdevs[0])
  s_errs_g.append(stdevs[1])
  m_errs_g.append(stdevs[2])
  
  #lognormal plot itself
  x = np.linspace(0.02, 0.6, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_g[i], yg[i], fmt = '.', yerr = menStd_g[i], capsize=5, label = 'Greedy Path')

  #plotting stuff
  plt.legend(prop={'size': 15})
  plt.xlabel('Greedy Path Protrusion', fontsize =20)
  plt.ylabel('Frequency', fontsize =20)
  plt.title(f'Protrusions for N={Ns[i]}, Realisations={realisations[i]}', fontsize =25)
  plt.xticks(size=20)
  plt.yticks(size=20)

plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_g[Key_Ns[i]], ydata=yg[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_g[Key_Ns[i]], yg[Key_Ns[i]], fmt = '.', yerr = menStd_g[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Protrusions of the Time-Greedy Path', fontsize = 30)
plt.xlabel(r'Protrusion, $\Delta x$', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()

"""**Greedy Path Parameter Scaling**"""

plt.figure(figsize=(20,20))
plt.suptitle('Greedy Path Protrusion Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_g, fmt='o', yerr=s_errs_g, capsize = 5)
plt.title("s Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("s", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)



plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_g, fmt='o', yerr=m_errs_g, capsize = 5)
plt.title("m Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)

#plt.subplot(3,3,3)
#plt.errorbar(Ns, a_s_g, fmt='o', yerr=a_errs_g, capsize = 5)
#plt.title("A scaling", fontsize =15)
#plt.xlabel("N, size of graph", fontsize =15)
#plt.ylabel("A", fontsize =15)
#plt.xscale('log')


plt.subplot(2,2,2)

plt.show()

"""**Lognormal Fits for Random Paths**"""

#defintions
s_s_r, m_s_r, a_s_r = [],[],[]
s_errs_r, m_errs_r, a_errs_r = [],[],[]

#figure stuff
plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Random Path Protrusion', fontsize = 30)

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_r[i], ydata=yr[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_r.append(pars[0])
  s_s_r.append(pars[1])
  m_s_r.append(pars[2])
  #parameter errors
  a_errs_r.append(stdevs[0])
  s_errs_r.append(stdevs[1])
  m_errs_r.append(stdevs[2])
  
  #lognormal plot itself
  x = np.linspace(0.02, 0.6, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_r[i], yr[i], fmt = '.', yerr = menStd_r[i], capsize=5, label = 'Random Path')

  #plotting stuff
  plt.legend(prop={'size': 20})
  plt.xlabel('Random Path Protrusion', fontsize =20)
  plt.ylabel('Frequency', fontsize =20)
  plt.title(f'Protrusions for N={Ns[i]}, Realisations={realisations[i]}', fontsize =25)
  plt.xticks(size=20)
  plt.yticks(size=20)

plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_r[Key_Ns[i]], ydata=yr[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_r[Key_Ns[i]], yr[Key_Ns[i]], fmt = '.', yerr = menStd_r[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Protrusions of the Random Path', fontsize = 30)
plt.xlabel(r'Protrusion, $\Delta x$', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()

"""**Random path scaling**"""

plt.figure(figsize=(20,20))
plt.suptitle('Random Path Protrusion Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_r, fmt='o', yerr=s_errs_r, capsize = 5)
plt.title("s Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("s", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)




plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_r, fmt='o', yerr=m_errs_r, capsize = 5)
plt.title("m Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)

#plt.subplot(4,4,3)
#plt.errorbar(Ns, a_s_r, fmt='o', yerr=a_errs_r, capsize = 5)
#plt.title("a scaling")
#plt.xlabel("N, size of graph")
#plt.ylabel("a")
#plt.xscale('log')


plt.subplot(2,2,2)
plt.show()

"""**m scaling**"""

#Log_10 of Ns
log_Ns = np.log10(Ns)

#figure stuff
plt.figure(figsize=(20,20))
plt.suptitle('Protrusion m-scaling Fittings', fontsize = 30)

#text description of fit
plt.subplot(2,2,1)
plt.text(0.5, 0.5,r'Fit: $m = \alpha log(N) + \beta$',
                ha='center', va='center', size=25)

#Longest Path
plt.subplot(2,2,2)
# fitting
pars_l,cov_l = curve_fit(f=straightline, xdata= log_Ns, ydata=m_s_l)
stdevs_l = np.sqrt(np.diag(cov_l))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_l), 'g--', label=fr' m = {pars_l[0]:.3f} $\pm$ {stdevs_l[0]:.3f} log(N) + {pars_l[1]:.2f} $\pm$ {stdevs_l[1]:.2f}')
plt.errorbar(log_Ns,m_s_l, color = 'green', fmt='o', yerr=m_errs_l, capsize = 5)
plt.legend(prop={'size': 17})
plt.title("Longest Path", fontsize = 25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

#Greedy Path
plt.subplot(2,2,3)
# fitting
pars_g,cov_g = curve_fit(f=straightline, xdata= log_Ns, ydata=m_s_g)
stdevs_g = np.sqrt(np.diag(cov_g))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_g), 'b--', label=fr' m = {pars_g[0]:.3f} $\pm$ {stdevs_g[0]:.3f} log(N) + {pars_g[1]:.2f} $\pm$ {stdevs_g[1]:.2f}')
plt.errorbar(log_Ns, m_s_g, color = 'blue',fmt='o', yerr=m_errs_g, capsize = 5)
plt.legend(prop={'size': 17})
plt.title("Greedy Path", fontsize =25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

#Random Path
plt.subplot(2,2,4)
#fitting
pars_r,cov_r = curve_fit(f=straightline, xdata = np.delete(log_Ns,0), ydata = np.delete(m_s_r,0))
stdevs_r = np.sqrt(np.diag(cov_r))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_r), 'r--', label=fr' m = {pars_r[0]:.3f} $\pm$ {stdevs_r[0]:.3f} log(N) + {pars_r[1]:.2f} $\pm$ {stdevs_r[1]:.2f}')
plt.errorbar(log_Ns, m_s_r, color = 'red',fmt='o', yerr=m_errs_r, capsize = 5)
plt.legend(prop={'size': 17})
plt.title("Random Path", fontsize =25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

plt.show()

"""**Comparing m's of Longest, Greedy, Random**"""

plt.figure(figsize=(15,15))
plt.title('Protrusion m-Fitting Comparisons', fontsize = 30)
#plots
plt.plot(log_Ns, straightline(log_Ns, *pars_l), 'g--', label = fr'Longest path, $\alpha =$ {pars_l[0]:.3f} $\pm$ {stdevs_l[0]:.3f}')
plt.errorbar(log_Ns, m_s_l, color = 'green',fmt='o', yerr=m_errs_l, capsize = 5)
plt.plot(log_Ns, straightline(log_Ns, *pars_g), 'b--', label = fr'Greedy path, $\alpha =$ {pars_g[0]:.3f} $\pm$ {stdevs_g[0]:.3f}' )
plt.errorbar(log_Ns, m_s_g, color = 'blue',fmt='o', yerr=m_errs_g, capsize = 5)
plt.plot(log_Ns, straightline(log_Ns, *pars_r), 'r--', label = fr'Random path, $\alpha =$ {pars_r[0]:.3f} $\pm$ {stdevs_r[0]:.3f} ')
plt.errorbar(log_Ns[1:], m_s_r[1:], color = 'red',fmt='o', yerr=m_errs_r[1:], capsize = 5)
#plot stuff
plt.grid()
plt.legend(prop ={'size':25})
plt.xlabel('$log_{10}$(N)', fontsize = 25)
plt.ylabel("m", fontsize=25)
plt.xticks(size=20)
plt.yticks(size=20)

plt.show()

print('greedy', pars_g)
print('longest',  pars_l)
print('random',  pars_r)

"""#**Wonkiness**

**extracting wonkiness**

Using get_angle_LRF to get wonkiness distribution. 

get_angle2_LRF is for extracting the mean per path
"""

'''Bins'''

bins = np.arange(0,45,5) # should be np.arange(0,50,5)? 
bincenters = 0.5*(bins[1:]+bins[:-1])
N_i = -1



'''
--------------------------------------------------------------------------------
SmallGraphs'''
#paths
l_S_wonky, g_S_wonky, r_S_wonky = [], [], [] 

#errors 
# standard error of the mean of the frequencies in each bin, for each graph size. List of arrays.
l_S_wonky_errs, g_S_wonky_errs, r_S_wonky_errs =[], [], [] 

#meanf
# mean frequency in each bin, for each graph size. List of arrays. 
l_S_wonky_meanf, g_S_wonky_meanf, r_S_wonky_meanf =[], [], []

#n_total
# mean (over realisations) total number of angles, for each graph size. List. 
l_S_wonky_nTotal, g_S_wonky_nTotal, r_S_wonky_nTotal =[], [], []

#n_errs
# standard error of the mean in the total frequency, for each graph size. 
l_S_wonky_nErrs, g_S_wonky_nErrs, r_S_wonky_nErrs =[], [], []

#Unpacking Wonkiness
for i in range(len(SmallGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_S_wonky, N_G_S_wonky, N_R_S_wonky = [], [], []
  
  for j in range(SmallGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle_LRF(SmallGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle_LRF(SmallGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle_LRF(SmallGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_S_wonky.append(angles_of_lp)
    N_G_S_wonky.append(angles_of_gp)
    N_R_S_wonky.append(angles_of_rp)
 
  l_S_wonky.append(N_L_S_wonky)
  g_S_wonky.append(N_G_S_wonky)
  r_S_wonky.append(N_R_S_wonky)

#Errors
for i in range(len(SmallGraphs_Ns)):
  l_S_freq, g_S_freq, r_S_freq =[], [], []
  l_S_n, g_S_n, r_S_n = [], [], []

  for j in range(SmallGraphs_realisations):
    yl_S, l_S_binEdges = np.histogram(l_S_wonky[i][j], bins=bins, density=False)
    yg_S, g_S_binEdges = np.histogram(g_S_wonky[i][j], bins=bins, density=False)
    yr_S, r_S_binEdges = np.histogram(r_S_wonky[i][j], bins=bins, density=False)

    l_S_freq.append(yl_S)
    g_S_freq.append(yg_S)
    r_S_freq.append(yr_S)

    l_S_n.append(np.sum(yl_S))
    g_S_n.append(np.sum(yg_S))
    r_S_n.append(np.sum(yr_S))
  
  l_S_freq = np.array(l_S_freq)
  g_S_freq = np.array(g_S_freq)
  r_S_freq = np.array(r_S_freq)

  l_S_wonky_meanf.append(np.mean(l_S_freq, axis=0))
  g_S_wonky_meanf.append(np.mean(g_S_freq, axis=0))
  r_S_wonky_meanf.append(np.mean(r_S_freq, axis=0))

  l_S_wonky_errs.append(np.std(l_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  g_S_wonky_errs.append(np.std(g_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  r_S_wonky_errs.append(np.std(r_S_freq, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))

  l_S_wonky_nTotal.append(np.mean(l_S_n))
  g_S_wonky_nTotal.append(np.mean(g_S_n))
  r_S_wonky_nTotal.append(np.mean(r_S_n))

  l_S_wonky_nErrs.append(np.std(l_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  g_S_wonky_nErrs.append(np.std(g_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))
  r_S_wonky_nErrs.append(np.std(r_S_n, axis=0, ddof=1)/np.sqrt(SmallGraphs_realisations))




'''
--------------------------------------------------------------------------------
BigGraphs'''

#paths
l_B_wonky, g_B_wonky, r_B_wonky = [], [], []

#errors
l_B_wonky_errs, g_B_wonky_errs, r_B_wonky_errs =[], [], []

#meanf
l_B_wonky_meanf, g_B_wonky_meanf, r_B_wonky_meanf =[], [], []

#n_total
l_B_wonky_nTotal, g_B_wonky_nTotal, r_B_wonky_nTotal =[], [], []

#n_errs
l_B_wonky_nErrs, g_B_wonky_nErrs, r_B_wonky_nErrs =[], [], []

#Unpacking Wonkiness
for i in range(len(BigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_B_wonky, N_G_B_wonky, N_R_B_wonky = [], [], []
  
  for j in range(BigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle_LRF(BigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle_LRF(BigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle_LRF(BigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_B_wonky.append(angles_of_lp)
    N_G_B_wonky.append(angles_of_gp)
    N_R_B_wonky.append(angles_of_rp)
 
  l_B_wonky.append(N_L_B_wonky)
  g_B_wonky.append(N_G_B_wonky)
  r_B_wonky.append(N_R_B_wonky)

#Errors
for i in range(len(BigGraphs_Ns)):
  l_B_freq, g_B_freq, r_B_freq =[], [], []
  l_B_n, g_B_n, r_B_n = [], [], []

  for j in range(BigGraphs_realisations):
    yl_B, l_B_binEdges = np.histogram(l_B_wonky[i][j], bins=bins, density=False)
    yg_B, g_B_binEdges = np.histogram(g_B_wonky[i][j], bins=bins, density=False)
    yr_B, r_B_binEdges = np.histogram(r_B_wonky[i][j], bins=bins, density=False)

    l_B_freq.append(yl_B)
    g_B_freq.append(yg_B)
    r_B_freq.append(yr_B)

    l_B_n.append(np.sum(yl_B))
    g_B_n.append(np.sum(yg_B))
    r_B_n.append(np.sum(yr_B))
  
  l_B_freq = np.array(l_B_freq)
  g_B_freq = np.array(g_B_freq)
  r_B_freq = np.array(r_B_freq)

  l_B_wonky_meanf.append(np.mean(l_B_freq, axis=0))
  g_B_wonky_meanf.append(np.mean(g_B_freq, axis=0))
  r_B_wonky_meanf.append(np.mean(r_B_freq, axis=0))

  l_B_wonky_errs.append(np.std(l_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  g_B_wonky_errs.append(np.std(g_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  r_B_wonky_errs.append(np.std(r_B_freq, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))

  l_B_wonky_nTotal.append(np.mean(l_B_n))
  g_B_wonky_nTotal.append(np.mean(g_B_n))
  r_B_wonky_nTotal.append(np.mean(r_B_n))

  l_B_wonky_nErrs.append(np.std(l_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  g_B_wonky_nErrs.append(np.std(g_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))
  r_B_wonky_nErrs.append(np.std(r_B_n, axis=0, ddof=1)/np.sqrt(BigGraphs_realisations))





'''
--------------------------------------------------------------------------------
BBigGraphs'''

#paths
l_BB_wonky, g_BB_wonky, r_BB_wonky = [], [], []

#errors
l_BB_wonky_errs, g_BB_wonky_errs, r_BB_wonky_errs =[], [], []

#meanf
l_BB_wonky_meanf, g_BB_wonky_meanf, r_BB_wonky_meanf =[], [], []

#n_total
l_BB_wonky_nTotal, g_BB_wonky_nTotal, r_BB_wonky_nTotal =[], [], []

#n_errs
l_BB_wonky_nErrs, g_BB_wonky_nErrs, r_BB_wonky_nErrs =[], [], []

#Unpacking Wonkiness
for i in range(len(BBigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_BB_wonky, N_G_BB_wonky, N_R_BB_wonky = [], [], []
  
  for j in range(BBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle_LRF(BBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle_LRF(BBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle_LRF(BBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BB_wonky.append(angles_of_lp)
    N_G_BB_wonky.append(angles_of_gp)
    N_R_BB_wonky.append(angles_of_rp)
 
  l_BB_wonky.append(N_L_BB_wonky)
  g_BB_wonky.append(N_G_BB_wonky)
  r_BB_wonky.append(N_R_BB_wonky)

#Errors
for i in range(len(BBigGraphs_Ns)):
  l_BB_freq, g_BB_freq, r_BB_freq =[], [], []
  l_BB_n, g_BB_n, r_BB_n = [], [], []

  for j in range(BBigGraphs_realisations):
    yl_BB, l_BB_binEdges = np.histogram(l_BB_wonky[i][j], bins=bins, density=False)
    yg_BB, g_BB_binEdges = np.histogram(g_BB_wonky[i][j], bins=bins, density=False)
    yr_BB, r_BB_binEdges = np.histogram(r_BB_wonky[i][j], bins=bins, density=False)

    l_BB_freq.append(yl_BB)
    g_BB_freq.append(yg_BB)
    r_BB_freq.append(yr_BB)

    l_BB_n.append(np.sum(yl_BB))
    g_BB_n.append(np.sum(yg_BB))
    r_BB_n.append(np.sum(yr_BB))
  
  l_BB_freq = np.array(l_BB_freq)
  g_BB_freq = np.array(g_BB_freq)
  r_BB_freq = np.array(r_BB_freq)

  l_BB_wonky_meanf.append(np.mean(l_BB_freq, axis=0))
  g_BB_wonky_meanf.append(np.mean(g_BB_freq, axis=0))
  r_BB_wonky_meanf.append(np.mean(r_BB_freq, axis=0))

  l_BB_wonky_errs.append(np.std(l_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  g_BB_wonky_errs.append(np.std(g_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  r_BB_wonky_errs.append(np.std(r_BB_freq, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))

  l_BB_wonky_nTotal.append(np.mean(l_BB_n))
  g_BB_wonky_nTotal.append(np.mean(g_BB_n))
  r_BB_wonky_nTotal.append(np.mean(r_BB_n))

  l_BB_wonky_nErrs.append(np.std(l_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  g_BB_wonky_nErrs.append(np.std(g_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))
  r_BB_wonky_nErrs.append(np.std(r_BB_n, axis=0, ddof=1)/np.sqrt(BBigGraphs_realisations))




'''
--------------------------------------------------------------------------------
BBBigGraphs'''

#paths
l_BBB_wonky, g_BBB_wonky, r_BBB_wonky = [], [], []

#errors
l_BBB_wonky_errs, g_BBB_wonky_errs, r_BBB_wonky_errs =[], [], []

#meanf
l_BBB_wonky_meanf, g_BBB_wonky_meanf, r_BBB_wonky_meanf =[], [], []

#n_total
l_BBB_wonky_nTotal, g_BBB_wonky_nTotal, r_BBB_wonky_nTotal =[], [], []

#n_errs
l_BBB_wonky_nErrs, g_BBB_wonky_nErrs, r_BBB_wonky_nErrs =[], [], []

#Unpacking Wonkiness
for i in range(len(BBBigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_BBB_wonky, N_G_BBB_wonky, N_R_BBB_wonky = [], [], []
  
  for j in range(BBBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle_LRF(BBBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle_LRF(BBBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle_LRF(BBBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BBB_wonky.append(angles_of_lp)
    N_G_BBB_wonky.append(angles_of_gp)
    N_R_BBB_wonky.append(angles_of_rp)
 
  l_BBB_wonky.append(N_L_BBB_wonky)
  g_BBB_wonky.append(N_G_BBB_wonky)
  r_BBB_wonky.append(N_R_BBB_wonky)


#Errors
for i in range(len(BBBigGraphs_Ns)):
  l_BBB_freq, g_BBB_freq, r_BBB_freq =[], [], []
  l_BBB_n, g_BBB_n, r_BBB_n = [], [], []

  for j in range(BBBigGraphs_realisations):
    yl_BBB, l_BBB_binEdges = np.histogram(l_BBB_wonky[i][j], bins=bins, density=False)
    yg_BBB, g_BBB_binEdges = np.histogram(g_BBB_wonky[i][j], bins=bins, density=False)
    yr_BBB, r_BBB_binEdges = np.histogram(r_BBB_wonky[i][j], bins=bins, density=False)

    l_BBB_freq.append(yl_BBB)
    g_BBB_freq.append(yg_BBB)
    r_BBB_freq.append(yr_BBB)

    l_BBB_n.append(np.sum(yl_BBB))
    g_BBB_n.append(np.sum(yg_BBB))
    r_BBB_n.append(np.sum(yr_BBB))
  
  l_BBB_freq = np.array(l_BBB_freq)
  g_BBB_freq = np.array(g_BBB_freq)
  r_BBB_freq = np.array(r_BBB_freq)

  l_BBB_wonky_meanf.append(np.mean(l_BBB_freq, axis=0))
  g_BBB_wonky_meanf.append(np.mean(g_BBB_freq, axis=0))
  r_BBB_wonky_meanf.append(np.mean(r_BBB_freq, axis=0))

  l_BBB_wonky_errs.append(np.std(l_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  g_BBB_wonky_errs.append(np.std(g_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  r_BBB_wonky_errs.append(np.std(r_BBB_freq, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))

  l_BBB_wonky_nTotal.append(np.mean(l_BBB_n))
  g_BBB_wonky_nTotal.append(np.mean(g_BBB_n))
  r_BBB_wonky_nTotal.append(np.mean(r_BBB_n))

  l_BBB_wonky_nErrs.append(np.std(l_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  g_BBB_wonky_nErrs.append(np.std(g_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))
  r_BBB_wonky_nErrs.append(np.std(r_BBB_n, axis=0, ddof=1)/np.sqrt(BBBigGraphs_realisations))

"""**Union**"""

#realisations union
realisations = [SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, BigGraphs_realisations, BigGraphs_realisations, BBigGraphs_realisations, BBigGraphs_realisations, BBBigGraphs_realisations]
#Ns union
Ns = SmallGraphs_Ns + BigGraphs_Ns + BBigGraphs_Ns + BBBigGraphs_Ns

#raw wonkiness union
l_wonky = l_S_wonky + l_B_wonky + l_BB_wonky + l_BBB_wonky
g_wonky = g_S_wonky + g_B_wonky + g_BB_wonky + g_BBB_wonky
r_wonky = r_S_wonky + r_B_wonky + r_BB_wonky + r_BBB_wonky

#nErrs union
l_wonky_nErrs = l_S_wonky_nErrs + l_B_wonky_nErrs + l_BB_wonky_nErrs + l_BBB_wonky_nErrs 
g_wonky_nErrs = g_S_wonky_nErrs + g_B_wonky_nErrs + g_BB_wonky_nErrs + g_BBB_wonky_nErrs
r_wonky_nErrs = r_S_wonky_nErrs + r_B_wonky_nErrs + r_BB_wonky_nErrs + r_BBB_wonky_nErrs

#meanf union
l_wonky_meanf = l_S_wonky_meanf + l_B_wonky_meanf + l_BB_wonky_meanf + l_BBB_wonky_meanf 
g_wonky_meanf = g_S_wonky_meanf + g_B_wonky_meanf + g_BB_wonky_meanf + g_BBB_wonky_meanf
r_wonky_meanf = r_S_wonky_meanf + r_B_wonky_meanf + r_BB_wonky_meanf + r_BBB_wonky_meanf

#nTotal union
l_wonky_nTotal = l_S_wonky_nTotal + l_B_wonky_nTotal + l_BB_wonky_nTotal + l_BBB_wonky_nTotal
g_wonky_nTotal = g_S_wonky_nTotal + g_B_wonky_nTotal + g_BB_wonky_nTotal + g_BBB_wonky_nTotal
r_wonky_nTotal = r_S_wonky_nTotal + r_B_wonky_nTotal + r_BB_wonky_nTotal + r_BBB_wonky_nTotal

#errs union
l_wonky_errs = l_S_wonky_errs +  l_B_wonky_errs + l_BB_wonky_errs + l_BBB_wonky_errs
g_wonky_errs = g_S_wonky_errs +  g_B_wonky_errs + g_BB_wonky_errs + g_BBB_wonky_errs
r_wonky_errs = r_S_wonky_errs +  r_B_wonky_errs + r_BB_wonky_errs + r_BBB_wonky_errs

"""**Plotting**"""

#plt.figure(figsize=(40,40))
#plt.suptitle('Wonkiness distribution from various graph sizes', fontsize=18)

for i in range(len(Ns)):
  #plt.subplot(4,4,i+1)
  
  plt.figure(figsize=(10,10))

  yl, l_binEdges = np.histogram(np.concatenate(l_wonky[i],axis = None), bins=bins, density=False)
  l_Nerror = np.sqrt((l_wonky_nErrs[i] * (l_wonky_meanf[i]/ (l_wonky_nTotal[i]**2)))**2 + (l_wonky_errs[i]/l_wonky_nTotal[i])**2)/5

  yg, g_binEdges = np.histogram(np.concatenate(g_wonky[i],axis = None), bins=bins, density=False)
  g_Nerror = np.sqrt((g_wonky_nErrs[i] * (g_wonky_meanf[i]/ (g_wonky_nTotal[i]**2)))**2 + (g_wonky_errs[i]/g_wonky_nTotal[i])**2)/5 

#  yr, r_binEdges = np.histogram(np.concatenate(r_wonky[i],axis = None), bins=bins, density=False)
#  r_Nerror = np.sqrt((r_wonky_nErrs[i] * (r_wonky_meanf[i]/ (r_wonky_nTotal[i]**2)))**2 + (r_wonky_errs[i]/r_wonky_nTotal[i])**2)/5 

  plt.errorbar(bincenters, yl/(5*len(np.concatenate(l_wonky[i],axis = None))), fmt ='.', yerr=l_Nerror, capsize=5, label='Longest path')
  plt.errorbar(bincenters, yg/(5*len(np.concatenate(g_wonky[i],axis = None))), fmt ='.', yerr=g_Nerror, capsize=5, label='Greedy path')
#  plt.errorbar(bincenters, yr/(5*len(np.concatenate(r_wonky[i],axis = None))), fmt ='.', yerr=r_Nerror, capsize=5, label='Random path')

  plt.legend(prop ={'size':25})
  plt.xlabel(r' $\phi$', fontsize = 25)
  plt.ylabel('Probability Density', fontsize = 25)
  plt.title(rf'Wonkiness for N={Ns[i]}, realisations={realisations[i]}', fontsize = 30)
  plt.xticks(size=20)
  plt.yticks(size=20)
  plt.show()

"""**plots without random path**"""

plt.figure(figsize=(40,40))
plt.suptitle('Wonkiness distribution from various graph sizes', fontsize=18)

diff = np.zeros(len(Ns))
diff_err = np.zeros(len(Ns))

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)
  
  yl, l_binEdges = np.histogram(np.concatenate(l_wonky[i],axis = None), bins=bins, density=False)
  l_Nerror = np.sqrt((l_wonky_nErrs[i] * (l_wonky_meanf[i]/ (l_wonky_nTotal[i]**2)))**2 + (l_wonky_errs[i]/l_wonky_nTotal[i])**2)/5

  yg, g_binEdges = np.histogram(np.concatenate(g_wonky[i],axis = None), bins=bins, density=False)
  g_Nerror = np.sqrt((g_wonky_nErrs[i] * (g_wonky_meanf[i]/ (g_wonky_nTotal[i]**2)))**2 + (g_wonky_errs[i]/g_wonky_nTotal[i])**2)/5

  prob_l = yl/(5*len(np.concatenate(l_wonky[i],axis = None)))
  prob_g = yg/(5*len(np.concatenate(g_wonky[i],axis = None)))
  
  for j in range(len(prob_l)):
    diff[i] += np.abs(prob_l[j] - prob_g[j])
    diff_err[i] += np.sqrt((l_Nerror[j])**2 + (g_Nerror[j])**2)

  plt.errorbar(bincenters, yl/(5*len(np.concatenate(l_wonky[i],axis = None))), fmt ='.', yerr=l_Nerror, capsize=5, label='longest path')
  plt.errorbar(bincenters, yg/(5*len(np.concatenate(g_wonky[i],axis = None))), fmt ='.', yerr=g_Nerror, capsize=5, label='greedy path')

  plt.legend(prop = {'size':25})
  plt.xlabel(r' $\phi$')
  plt.ylabel('prob density')
  plt.xticks(size=20)
  plt.yticks(size=20)
  plt.title(rf'$\phi$ distribition, graph size {Ns[i]}, realisations: {realisations[i]}')


plt.show()

plt.figure(figsize=(10,10))
plt.title('Difference between Greedy and Longest Path Wonkiness', fontsize = 30)
pars_diff,cov_diff = curve_fit(f=straightline, xdata= np.log10(Ns), ydata=diff)
plt.plot(np.log10(Ns), straightline(np.log10(Ns), *pars_diff), 'g--')
plt.errorbar(np.log10(Ns), diff, fmt ='.', yerr = diff_err, capsize= 5)
plt.ylabel('Difference in Probability Density', fontsize =25)
plt.xlabel('N, Size of Graph', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.show()

plt.figure(figsize=(10,10))
plt.title('Difference between Greedy and Longest Path Wonkiness', fontsize = 30)
pars_diff,cov_diff = curve_fit(f=straightline, xdata= np.log10(Ns), ydata=diff)
plt.plot(np.log10(Ns), straightline(np.log10(Ns), *pars_diff), 'g--')
plt.errorbar(np.log10(Ns), diff, fmt ='.')
plt.ylabel('Difference in Probability Density', fontsize = 25)
plt.xlabel('N, Size of Graph', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.show()

"""**Mean Wonkiness**

looking at mean wonkiness/path instead of the full distribution
"""

'''Bins'''

bins = np.arange(0,45,5)
bincenters = 0.5*(bins[1:]+bins[:-1])
N_i = -1



'''
--------------------------------------------------------------------------------
SmallGraphs'''
#paths
l_S_wonky2, g_S_wonky2, r_S_wonky2 = [], [], [] 

#Unpacking Wonkiness2
for i in range(len(SmallGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_S_wonky2, N_G_S_wonky2, N_R_S_wonky2 = [], [], []
  
  for j in range(SmallGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle2_LRF(SmallGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle2_LRF(SmallGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle2_LRF(SmallGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_S_wonky2.append(angles_of_lp)
    N_G_S_wonky2.append(angles_of_gp)
    N_R_S_wonky2.append(angles_of_rp)
 
  l_S_wonky2.append(N_L_S_wonky2)
  g_S_wonky2.append(N_G_S_wonky2)
  r_S_wonky2.append(N_R_S_wonky2)




'''
--------------------------------------------------------------------------------
BigGraphs'''

#paths
l_B_wonky2, g_B_wonky2, r_B_wonky2 = [], [], []

#Unpacking Wonkiness2
for i in range(len(BigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_B_wonky2, N_G_B_wonky2, N_R_B_wonky2 = [], [], []
  
  for j in range(BigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle2_LRF(BigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle2_LRF(BigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle2_LRF(BigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_B_wonky2.append(angles_of_lp)
    N_G_B_wonky2.append(angles_of_gp)
    N_R_B_wonky2.append(angles_of_rp)
 
  l_B_wonky2.append(N_L_B_wonky2)
  g_B_wonky2.append(N_G_B_wonky2)
  r_B_wonky2.append(N_R_B_wonky2)




'''
--------------------------------------------------------------------------------
BBigGraphs'''

#paths
l_BB_wonky2, g_BB_wonky2, r_BB_wonky2 = [], [], []

#Unpacking Wonkiness2
for i in range(len(BBigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_BB_wonky2, N_G_BB_wonky2, N_R_BB_wonky2 = [], [], []
  
  for j in range(BBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle2_LRF(BBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle2_LRF(BBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle2_LRF(BBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BB_wonky2.append(angles_of_lp)
    N_G_BB_wonky2.append(angles_of_gp)
    N_R_BB_wonky2.append(angles_of_rp)
 
  l_BB_wonky2.append(N_L_BB_wonky2)
  g_BB_wonky2.append(N_G_BB_wonky2)
  r_BB_wonky2.append(N_R_BB_wonky2)




'''
--------------------------------------------------------------------------------
BBBigGraphs'''

#paths
l_BBB_wonky2, g_BBB_wonky2, r_BBB_wonky2 = [], [], []

#Unpacking Wonkiness2
for i in range(len(BBBigGraphs_Ns)):
  #for each N-node graph, initialise number of wonky stuff measured
  N_L_BBB_wonky2, N_G_BBB_wonky2, N_R_BBB_wonky2 = [], [], []
  
  for j in range(BBBigGraphs_realisations):
    #for each realisation of an N node graph, get the angles for the 3 path types
    angles_of_lp = np.array(get_angle2_LRF(BBBigGraphs_longest_path_points[i][j])) / (np.pi/180)
    angles_of_gp = np.array(get_angle2_LRF(BBBigGraphs_greedy_path_points[i][j])) / (np.pi/180)
    angles_of_rp = np.array(get_angle2_LRF(BBBigGraphs_random_path_points[i][j])) / (np.pi/180)
    
    #add in those angles to this array
    N_L_BBB_wonky2.append(angles_of_lp)
    N_G_BBB_wonky2.append(angles_of_gp)
    N_R_BBB_wonky2.append(angles_of_rp)
 
  l_BBB_wonky2.append(N_L_BBB_wonky2)
  g_BBB_wonky2.append(N_G_BBB_wonky2)
  r_BBB_wonky2.append(N_R_BBB_wonky2)

"""**Union again**"""

#raw wonkiness2 union
l_wonky2 = l_S_wonky2 + l_B_wonky2 + l_BB_wonky2 + l_BBB_wonky2
g_wonky2 = g_S_wonky2 + g_B_wonky2 + g_BB_wonky2 + g_BBB_wonky2
r_wonky2 = r_S_wonky2 + r_B_wonky2 + r_BB_wonky2 + r_BBB_wonky2

#no special errors

# Consider adding a curvefit for a gaussian to extract true mean and spread


# definitions
yl, yg, yr = [0]*12,[0]*12,[0]*12
binEdge_l, binEdge_g, binEdge_r = [0]*12,[0]*12,[0]*12
binCenters_l, binCenters_g, binCenters_r = [0]*12,[0]*12,[0]*12
menStd_l, menStd_g, menStd_r = [0]*12,[0]*12,[0]*12

# Main plot
plt.figure(figsize=(40,40))
plt.suptitle('Mean Wonkiness of Path Distribution for Different Graph Sizes', fontsize= 18)

# subplots
for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  # longest
  yl[i], binEdge_l[i] = np.histogram(np.concatenate(l_wonky2[i], axis = None), bins = 20, density = False)
  binCenters_l[i] = 0.5*(binEdge_l[i][1:] + binEdge_l[i][:-1])
  menStd_l[i] = np.sqrt(yl[i])

  plt.errorbar(binCenters_l[i], yl[i], fmt = '.', yerr = menStd_l[i], capsize=5, label = 'Longest Path')

  # greedy
  yg[i], binEdge_g[i] = np.histogram(np.concatenate(g_wonky2[i], axis = None), bins = 20, density = False)
  binCenters_g[i] = 0.5*(binEdge_g[i][1:] + binEdge_g[i][:-1])
  menStd_g[i] = np.sqrt(yg[i])

  plt.errorbar(binCenters_g[i], yg[i], fmt = '.', yerr = menStd_g[i], capsize=5, label = 'Greedy Path')

  # random
  yr[i], binEdge_r[i] = np.histogram(np.concatenate(r_wonky2[i], axis = None), bins = 20, density = False)
  binCenters_r[i] = 0.5*(binEdge_r[i][1:] + binEdge_r[i][:-1])
  menStd_r[i] = np.sqrt(yr[i])

  plt.errorbar(binCenters_r[i], yr[i], fmt = '.', yerr = menStd_r[i], capsize=5, label = 'Random Path')
  
  # graph stuff
  plt.legend()
  plt.xlabel('Mean Wonkiness')
  plt.ylabel('Frequency')
  plt.title(f'Mean Wonkiness Distribution in graph size {Ns[i]}, realisations: {realisations[i]}')

plt.show()

#mean - N

"""**Momentum**

just gonna use tan(wonkiness data) to fetch the momentum
"""

l_momentum = []
g_momentum = []
r_momentum = []
for i in range(len(Ns)):
  l_momentum.append([])
  g_momentum.append([])
  r_momentum.append([])
  for j in range(realisations[i]):
    l_momentum[i].append(np.abs(np.tan(l_wonky[i][j])))
    g_momentum[i].append(np.abs(np.tan(g_wonky[i][j])))
    r_momentum[i].append(np.abs(np.tan(r_wonky[i][j])))

"""Having a bit of trouble figuring out how to plot this ngl


path type_momentum[size of Graph][Realisation] is a list of different momenta

*for each size of graph:*

Want to plot Frequency on vertical axis, momenta bins on horizontal axis

*also want:*
mean momentum on vertical axis, N on horizontal axis


"""



"""#**Deviation**

**Calculating Deviations**
"""

'''
--------------------------------------------------------------------------------
SmallGraphs'''
#paths
l_S_area, g_S_area, r_S_area = [], [], [] 

#Unpacking area
for i in range(len(SmallGraphs_Ns)):
  #for each N-node graph, initialise areas measured
  N_L_S_area, N_G_S_area, N_R_S_area = [], [], []
  
  for j in range(SmallGraphs_realisations):
    #add in those areas to this array
    N_L_S_area.append(area(SmallGraphs_longest_path_points[i][j]))
    N_G_S_area.append(area(SmallGraphs_greedy_path_points[i][j]))
    N_R_S_area.append(area(SmallGraphs_random_path_points[i][j]))
 
  l_S_area.append(N_L_S_area)
  g_S_area.append(N_G_S_area)
  r_S_area.append(N_R_S_area)
  



'''
--------------------------------------------------------------------------------
BigGraphs'''
#paths
l_B_area, g_B_area, r_B_area = [], [], [] 

#Unpacking Protrusion
for i in range(len(BigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_B_area, N_G_B_area, N_R_B_area = [], [], []
  
  for j in range(BigGraphs_realisations):
    #add in those angles to this array
    N_L_B_area.append(area(BigGraphs_longest_path_points[i][j]))
    N_G_B_area.append(area(BigGraphs_greedy_path_points[i][j]))
    N_R_B_area.append(area(BigGraphs_random_path_points[i][j]))
 
  l_B_area.append(N_L_B_area)
  g_B_area.append(N_G_B_area)
  r_B_area.append(N_R_B_area)




'''
--------------------------------------------------------------------------------
BBigGraphs'''
#paths
l_BB_area, g_BB_area, r_BB_area = [], [], [] 

#Unpacking Protrusion
for i in range(len(BBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BB_area, N_G_BB_area, N_R_BB_area = [], [], []
  
  for j in range(BBigGraphs_realisations):
    #add in those angles to this array
    N_L_BB_area.append(area(BBigGraphs_longest_path_points[i][j]))
    N_G_BB_area.append(area(BBigGraphs_greedy_path_points[i][j]))
    N_R_BB_area.append(area(BBigGraphs_random_path_points[i][j]))
 
  l_BB_area.append(N_L_BB_area)
  g_BB_area.append(N_G_BB_area)
  r_BB_area.append(N_R_BB_area)




'''
--------------------------------------------------------------------------------
BBBigGraphs'''
#paths
l_BBB_area, g_BBB_area, r_BBB_area = [], [], [] 

#Unpacking Protrusion
for i in range(len(BBBigGraphs_Ns)):
  #for each N-node graph, initialise number of jagged stuff measured
  N_L_BBB_area, N_G_BBB_area, N_R_BBB_area = [], [], []
  
  for j in range(BBBigGraphs_realisations):
    #add in those angles to this array
    N_L_BBB_area.append(area(BBBigGraphs_longest_path_points[i][j]))
    N_G_BBB_area.append(area(BBBigGraphs_greedy_path_points[i][j]))
    N_R_BBB_area.append(area(BBBigGraphs_random_path_points[i][j]))
 
  l_BBB_area.append(N_L_BBB_area)
  g_BBB_area.append(N_G_BBB_area)
  r_BBB_area.append(N_R_BBB_area)

"""**Union of Data**"""

#realisations union
realisations = [SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, SmallGraphs_realisations, BigGraphs_realisations, BigGraphs_realisations, BBigGraphs_realisations, BBigGraphs_realisations, BBBigGraphs_realisations]
#Ns union
Ns = SmallGraphs_Ns + BigGraphs_Ns + BBigGraphs_Ns + BBBigGraphs_Ns

#raw area union
l_area = l_S_area + l_B_area + l_BB_area + l_BBB_area
g_area = g_S_area + g_B_area + g_BB_area + g_BBB_area
r_area = r_S_area + r_B_area + r_BB_area + r_BBB_area

#no special errors to merge

"""**Basic Plots**"""

#definitions
yl, yg, yr = [0]*12,[0]*12,[0]*12
binEdge_l, binEdge_g, binEdge_r = [0]*12,[0]*12,[0]*12
binCenters_l, binCenters_g, binCenters_r = [0]*12,[0]*12,[0]*12
menStd_l, menStd_g, menStd_r = [0]*12,[0]*12,[0]*12

#Main plot
plt.figure(figsize=(40,40))
plt.suptitle('Deviation distribution from various graph sizes', fontsize= 18)

#subplots
for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #longest
  yl[i], binEdge_l[i] = np.histogram(l_area[i], bins = 20, density = False)
  binCenters_l[i] = 0.5*(binEdge_l[i][1:] + binEdge_l[i][:-1])
  menStd_l[i] = np.sqrt(yl[i])

  plt.errorbar(binCenters_l[i], yl[i], fmt = '.', yerr = menStd_l[i], capsize=5, label = 'Longest Path')

  #greedy
  yg[i], binEdge_g[i] = np.histogram(g_area[i], bins = 20, density = False)
  binCenters_g[i] = 0.5*(binEdge_g[i][1:] + binEdge_g[i][:-1])
  menStd_g[i] = np.sqrt(yg[i])

  plt.errorbar(binCenters_g[i], yg[i], fmt = '.', yerr = menStd_g[i], capsize=5, label = 'Greedy Path')

  #random
  yr[i], binEdge_r[i] = np.histogram(r_area[i], bins = 20, density = False)
  binCenters_r[i] = 0.5*(binEdge_r[i][1:] + binEdge_r[i][:-1])
  menStd_r[i] = np.sqrt(yr[i])

  plt.errorbar(binCenters_r[i], yr[i], fmt = '.', yerr = menStd_r[i], capsize=5, label = 'Random Path')
  
  #graph stuff
  plt.legend()
  plt.xlabel('Deviation')
  plt.ylabel('Frequency')
  plt.title(f'Deviation in graph size {Ns[i]}, realisations: {realisations[i]}')

plt.show()

#tidy lognormal


Do_graphs = [1, 3, 6]
colours = ['#c44409', '#286f29', '#021461']
fig, ax = plt.subplots(figsize=(7.5,6))

for i in range(len(Do_graphs)):
    y2_l, binEdges2_l = np.histogram(l_roughness[Do_graphs[i]],bins=20, density=False)
    bincenters2_l = 0.5*(binEdges2_l[1:]+binEdges2_l[:-1])
    menStd2_l = np.sqrt(y2_l)

#fitting:






    #plt.errorbar(bincenters2_l[::2], y2_l[::2], fmt='.', color=colours[i], yerr=menStd2_l[::2], capsize = 5, alpha=0.45)
    plt.errorbar(bincenters2_l, y2_l, fmt='.', color=colours[i], yerr=menStd2_l, capsize = 5, alpha=0.4)
    x = np.linspace(0.02, 0.6, 100)
    plt.plot(x, lognormal(x, *params_l[Do_graphs[i]]), color=colours[i],  label = f'N = {Ns[Do_graphs[i]]}')

    plt.xlabel(r'Protrusion, $\Delta x$', fontsize=30)
    plt.ylabel('Frequency', fontsize=30)
#plt.title('Longest Paths', size=30)
plt.xticks(size=20)
plt.yticks(size=20)
ax.set_xticks([0, 0.3, 0.6])
ax.set_yticks([0,140])
plt.legend(prop={'size': 20})
#plt.savefig('lpath_prot_poster.png', bbox_inches='tight')
#files.download('lpath_prot_poster.png') 

plt.show()

"""**Lognormal fits - longest**"""

#defintions
s_s_l, m_s_l, a_s_l = [],[],[]
s_errs_l, m_errs_l, a_errs_l = [],[],[]

#figure stuff
plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Longest Path Deviation', fontsize = 30)

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_l[i], ydata=yl[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_l.append(pars[0])
  s_s_l.append(pars[1])
  m_s_l.append(pars[2])
  #parameter errors
  a_errs_l.append(stdevs[0])
  s_errs_l.append(stdevs[1])
  m_errs_l.append(stdevs[2])
  
  #lognormal plot itself
  x = np.linspace(0.01, 0.5, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'Fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_l[i], yl[i], fmt = '.', yerr = menStd_l[i], capsize=5, label = 'Longest Path')

  #plotting stuff
  plt.legend(prop = {'size':19})
  plt.xlabel('Longest Path Deviation', fontsize = 20)
  plt.ylabel('Frequency', fontsize = 20)
  plt.title(f'Deviations for N={Ns[i]}, Realisations={realisations[i]}', fontsize = 25)
  plt.xticks(size=20)
  plt.yticks(size=20)

plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_l[Key_Ns[i]], ydata=yl[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_l[Key_Ns[i]], yl[Key_Ns[i]], fmt = '.', yerr = menStd_l[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Deviations of the Longest Path', fontsize = 30)
plt.xlabel(r'Deviation', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()

"""**Parameter scalings - Longest**"""

plt.figure(figsize=(20,20))
plt.suptitle('Longest Path Deviation Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_l, fmt='o', yerr=s_errs_l, capsize = 5)
plt.title("s Scaling", fontsize = 25)
plt.xlabel("N, Size of Graph", fontsize = 20)
plt.ylabel("s", fontsize = 20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)



plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_l, fmt='o', yerr=m_errs_l, capsize = 5)
plt.title("m Scaling", fontsize = 25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize = 20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)

plt.subplot(2,2,2)
plt.show()

"""**Lognormal fitting - greedy**"""

#defintions
s_s_g, m_s_g, a_s_g = [],[],[]
s_errs_g, m_errs_g, a_errs_g = [],[],[]

#figure stuff
plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Greedy Path Deviations', fontsize = 30)

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_g[i], ydata=yg[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_g.append(pars[0])
  s_s_g.append(pars[1])
  m_s_g.append(pars[2])
  #parameter errors
  a_errs_g.append(stdevs[0])
  s_errs_g.append(stdevs[1])
  m_errs_g.append(stdevs[2])
  
  #lognormal plot itself
  x = np.linspace(0.01, 0.5, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_g[i], yg[i], fmt = '.', yerr = menStd_g[i], capsize=5, label = 'Greedy Path')

  #plotting stuff
  plt.legend(prop = {'size':19})
  plt.xlabel('Greedy Path Deviation', fontsize =20)
  plt.ylabel('Frequency', fontsize =20)
  plt.title(f'Deviations for N={Ns[i]}, Realisations={realisations[i]}', fontsize = 25)
  plt.xticks(size=20)
  plt.yticks(size=20)

plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_g[Key_Ns[i]], ydata=yg[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_g[Key_Ns[i]], yg[Key_Ns[i]], fmt = '.', yerr = menStd_g[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Deviations of the Time-Greedy Path', fontsize = 30)
plt.xlabel(r'Deviation', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()

"""**Parameter scaling - greedy**"""

plt.figure(figsize=(20,20))
plt.suptitle('Greedy Path Deviation Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_g, fmt='o', yerr=s_errs_g, capsize = 5)
plt.title("s Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("s", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)



plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_g, fmt='o', yerr=m_errs_g, capsize = 5)
plt.title("m Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)

#plt.subplot(4,4,3)
#plt.errorbar(Ns, a_s_g, fmt='o', yerr=a_errs_g, capsize = 5)
#plt.title("a scaling")
#plt.xlabel("N, size of graph")
#plt.ylabel("a")
#plt.xscale('log')


plt.subplot(2,2,2)

plt.show()

"""**Lognormal fittings - random**"""

#defintions
s_s_r, m_s_r, a_s_r = [],[],[]
s_errs_r, m_errs_r, a_errs_r = [],[],[]

#figure stuff
plt.figure(figsize=(40,40))
plt.suptitle('Lognormal Fit of Random Path Deviations', fontsize = 30)

for i in range(len(Ns)):
  plt.subplot(4,4,i+1)

  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_r[i], ydata=yr[i], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))
  #parameters
  a_s_r.append(pars[0])
  s_s_r.append(pars[1])
  m_s_r.append(pars[2])
  #parameter errors
  a_errs_r.append(stdevs[0])
  s_errs_r.append(stdevs[1])
  m_errs_r.append(stdevs[2])
  
  #lognormal plot itself

  x = np.linspace(0.01, 0.5, 100)
  plt.plot(x, lognormal(x, *pars), 'g--', label = 'fit:A=%5.3f, s=%5.3f, m=%5.3f' % tuple(pars))
  #errors plot
  plt.errorbar(binCenters_r[i], yr[i], fmt = '.', yerr = menStd_r[i], capsize=5, label = 'Random Path')

  #plotting stuff
  plt.legend(prop = {'size':19})
  plt.xlabel('Random Path Deviation', fontsize = 20)
  plt.ylabel('Frequency', fontsize = 20)
  plt.title(f'Deviations for N={Ns[i]}, Realisations={realisations[i]}', fontsize = 25)
  plt.xticks(size=20)
  plt.yticks(size=20)

plt.subplot(4,4,13)
plt.text(0.5, 0.5, 'Lognormal distribution\n' r'$\frac{A}{x s \sqrt{2 \pi}} exp \left( - \frac{(ln(x) - m)^{2}}{2 s^{2}} \right)$ ',
                ha='center', va='center', size=25)

plt.show()

Key_Ns = [1,3,6]

plt.figure(figsize =(10,10))
colours = ['#ff8000', '#008000', '#2e2be2']


for i in range(len(Key_Ns)):
  #fitting
  pars, cov = curve_fit(f=lognormal, xdata=binCenters_r[Key_Ns[i]], ydata=yr[Key_Ns[i]], p0=[20,0.4,-np.log(5)], bounds = (-np.inf, np.inf))
  stdevs= np.sqrt(np.diag(cov))

  #plotting
  x = np.linspace(0.02, 0.6, 500)
  plt.plot(x, lognormal(x, *pars), color = colours[i])
  plt.errorbar(binCenters_r[Key_Ns[i]], yr[Key_Ns[i]], fmt = '.', yerr = menStd_r[Key_Ns[i]], color = colours[i], capsize=5, label = f'N = {Ns[Key_Ns[i]]}')

plt.title('Deviations of the Random Path', fontsize = 30)
plt.xlabel(r'Deviation', fontsize = 25)
plt.ylabel('Frequency', fontsize = 25)
plt.xticks(size=20)
plt.yticks(size=20)
plt.legend(prop={'size': 25})
plt.show()

"""**parameter scalings - Random**"""

plt.figure(figsize=(20,20))
plt.suptitle('Random Path Deviation Fits - Lognormal Parameter Scaling', fontsize=30)

plt.subplot(2,2,1)
plt.errorbar(Ns, s_s_r, fmt='o', yerr=s_errs_r, capsize = 5)
plt.title("s Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("s", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)



plt.subplot(2,2,2)
plt.errorbar(Ns, m_s_r, fmt='o', yerr=m_errs_r, capsize = 5)
plt.title("m Scaling", fontsize =25)
plt.xlabel("N, Size of Graph", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xscale('log')
plt.xticks(size=20)
plt.yticks(size=20)

#plt.subplot(4,4,3)
#plt.errorbar(Ns, a_s_r, fmt='o', yerr=a_errs_r, capsize = 5)
#plt.title("a scaling")
#plt.xlabel("N, size of graph")
#plt.ylabel("a")
#plt.xscale('log')


plt.subplot(2,2,2)
plt.show()

"""**m scaling**"""

#Log_10 of Ns
log_Ns = np.log10(Ns)

#figure stuff
plt.figure(figsize=(20,20))
plt.suptitle('Deviation m-scaling Fittings', fontsize = 30)

#text description of fit
plt.subplot(2,2,1)
plt.text(0.5, 0.5,r'Fit: $m = \alpha log(N) + \beta$',
                ha='center', va='center', size=25)

#Longest Path
plt.subplot(2,2,2)
# fitting
pars_l,cov_l = curve_fit(f=straightline, xdata= log_Ns, ydata=m_s_l)
stdevs_l = np.sqrt(np.diag(cov_l))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_l), 'g--', label=fr' m = {pars_l[0]:.3f} $\pm$ {stdevs_l[0]:.3f} log(N) + {pars_l[1]:.2f} $\pm$ {stdevs_l[1]:.2f}')
plt.errorbar(log_Ns, m_s_l, color = 'green', fmt='o', yerr=m_errs_l, capsize = 5)
plt.title("Longest Path", fontsize =25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

#Greedy Path
plt.subplot(2,2,3)
# fitting
pars_g,cov_g = curve_fit(f=straightline, xdata= log_Ns, ydata=m_s_g)
stdevs_g = np.sqrt(np.diag(cov_g))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_g), 'b--', label=fr' m = {pars_g[0]:.3f} $\pm$ {stdevs_g[0]:.3f} log(N) + {pars_g[1]:.2f} $\pm$ {stdevs_g[1]:.2f}')
plt.errorbar(log_Ns, m_s_g, color = 'blue',fmt='o', yerr=m_errs_g, capsize = 5)
plt.title("Greedy Path", fontsize =25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

#Random Path
plt.subplot(2,2,4)
#fitting
pars_r,cov_r = curve_fit(f=straightline, xdata = np.delete(log_Ns,0), ydata = np.delete(m_s_r,0))
stdevs_r = np.sqrt(np.diag(cov_r))
# plotting
plt.plot(log_Ns, straightline(log_Ns, *pars_r), 'r--', label=fr' r = {pars_g[0]:.3f} $\pm$ {stdevs_r[0]:.3f} log(N) + {pars_r[1]:.2f} $\pm$ {stdevs_r[1]:.2f}')
plt.errorbar(log_Ns, m_s_r, color = 'red',fmt='o', yerr=m_errs_r, capsize = 5)
plt.title("Random Path", fontsize =25)
plt.xlabel("$log_{10}$(N)", fontsize =20)
plt.ylabel("m", fontsize =20)
plt.xticks(size=20)
plt.yticks(size=20)

plt.show()

"""**Comparing them together**"""

plt.figure(figsize=(15,15))
plt.title('Deviation m-Fitting Comparisons', fontsize =30)
#plots
plt.plot(log_Ns, straightline(log_Ns, *pars_l), 'g--', label = fr'Longest path, $\alpha =$ {pars_l[0]:.3f} $\pm$ {stdevs_l[0]:.3f}')
plt.errorbar(log_Ns, m_s_l, color = 'green',fmt='o', yerr=m_errs_l, capsize = 5)
plt.plot(log_Ns, straightline(log_Ns, *pars_g), 'b--', label = fr'Greedy path, $\alpha =$ {pars_g[0]:.3f} $\pm$ {stdevs_g[0]:.3f}' )
plt.errorbar(log_Ns, m_s_g, color = 'blue',fmt='o', yerr=m_errs_g, capsize = 5)
plt.plot(log_Ns, straightline(log_Ns, *pars_r), 'r--', label = fr'Random path, $\alpha =$ {pars_r[0]:.3f} $\pm$ {stdevs_r[0]:.3f} ')
plt.errorbar(log_Ns[1:], m_s_r[1:], color = 'red',fmt='o', yerr=m_errs_r[1:], capsize = 5)
#plot stuff
plt.grid()
plt.legend(prop ={'size':25})
plt.xlabel('$log_{10}$(N)', fontsize = 25)
plt.ylabel("m", fontsize=25)
plt.xticks(size=20)
plt.yticks(size=20)

plt.show()

print(pars_g, pars_l, pars_r)

np.sqrt(cov_r[0][0])